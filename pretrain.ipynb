{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df559d6ecf587ef4",
   "metadata": {},
   "source": [
    "# Pre-Training Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6487069a22b443e",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoImageProcessor\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from huggingface_hub import login as hf_login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaebb5e60434fc75",
   "metadata": {},
   "source": [
    "### Huggingface login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96406df8351e29f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment out the line below when you need to login to Huggingface\n",
    "hf_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88444867b0b14178",
   "metadata": {},
   "source": [
    "### Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e70cad906b1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae5ca44145e20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA Device Number\n",
    "DEVICE_NUM = 0\n",
    "\n",
    "device = torch.device(f\"cuda:{DEVICE_NUM}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"INFO: Using device - {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f33be18440cabc",
   "metadata": {},
   "source": [
    "## Load DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41127ff906823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reo_gia.datasets import ImageNet1K, CIFAR100, CIFAR10, DatasetHolder, build_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327d472ec0525e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = path.join(\".\", \"data\")\n",
    "\n",
    "IMAGENET1Ks = DatasetHolder(\n",
    "    train=ImageNet1K(root=DATA_ROOT, force_download=False, train=True, transform=build_augmentation(ImageNet1K.img_size)),\n",
    "    valid=ImageNet1K(root=DATA_ROOT, force_download=False, valid=True),\n",
    "    test=ImageNet1K(root=DATA_ROOT, force_download=False, train=False)\n",
    ")\n",
    "print(f\"INFO: Dataset loaded successfully - {IMAGENET1Ks}\")\n",
    "\n",
    "CIFAR100s = DatasetHolder(\n",
    "    train=CIFAR100(root=DATA_ROOT, download=True, train=True, transform=build_augmentation(CIFAR100.img_size)),\n",
    "    test=CIFAR100(root=DATA_ROOT, download=True, train=False)\n",
    ").split_train_valid()\n",
    "print(f\"INFO: Dataset loaded successfully - {CIFAR100s}\")\n",
    "\n",
    "CIFAR10s = DatasetHolder(\n",
    "    train=CIFAR10(root=DATA_ROOT, download=True, train=True, transform=build_augmentation(CIFAR10.img_size)),\n",
    "    test=CIFAR10(root=DATA_ROOT, download=True, train=False)\n",
    ").split_train_valid()\n",
    "print(f\"INFO: Dataset loaded successfully - {CIFAR10s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4aa8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChosenDataset: DatasetHolder = CIFAR10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfaaf862a9a0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Configuration\n",
    "dataset_config = ChosenDataset.config\n",
    "dataset_name = ChosenDataset.dataset_name\n",
    "num_classes = ChosenDataset.num_classes\n",
    "\n",
    "print(f\"INFO: Dataset Size - {ChosenDataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d5ea2a2af0c35d",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddcb2d583a637f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reo_gia.models import (\n",
    "    BaseModel,\n",
    "    # Target Models\n",
    "    ViTSmall, ViTBase, SwinTiny, SwinSmall,\n",
    "    # Compare Models\n",
    "    ConvNeXtTiny, ConvNeXtSmall, ResNet34, ResNet50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec83b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetModel: BaseModel = ConvNeXtTiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3500011660e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Model\n",
    "TargetModel.dataset_name = dataset_name\n",
    "\n",
    "model = TargetModel.from_pretrained(num_classes=num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TargetModel in [SwinTiny, SwinSmall]:  # Apply Swin-specific configuration\n",
    "    if 'size' in dataset_config:\n",
    "        del dataset_config['size']\n",
    "\n",
    "# Load Image Processor\n",
    "processor = AutoImageProcessor.from_pretrained(model.model_id)#, **dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f914f6148a87ae7",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ecd5b0e916b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(lst):\n",
    "    try:\n",
    "        return sum(lst) / len(lst)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 512, 512, 512\n",
    "#BATCH_SIZE = list(map(len, [ChosenDataset.train, ChosenDataset.valid, ChosenDataset.test]))\n",
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06a7d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    images = processor(images=list(images), return_tensors=\"pt\")[\"pixel_values\"]\n",
    "    labels = torch.tensor(labels)\n",
    "    return images, labels\n",
    "\n",
    "loader_config = dict(collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROCESSING = True  # Set False if DataLoader is causing issues\n",
    "\n",
    "from platform import system\n",
    "if MULTI_PROCESSING and system() != \"Windows\":  # Multiprocess data loading is not supported on Windows\n",
    "    import multiprocessing\n",
    "    cpu_cores = multiprocessing.cpu_count()\n",
    "    loader_config['num_workers'] = cpu_cores\n",
    "    print(f\"INFO: Number of CPU cores - {cpu_cores}\")\n",
    "else:\n",
    "    cpu_cores = 0\n",
    "    print(\"INFO: Using DataLoader without multi-processing.\")\n",
    "\n",
    "train_loader = DataLoader(ChosenDataset.train, batch_size=BATCH_SIZE[0], shuffle=True, **loader_config)\n",
    "valid_loader = DataLoader(ChosenDataset.valid, batch_size=BATCH_SIZE[1], shuffle=False, **loader_config)\n",
    "test_loader = DataLoader(ChosenDataset.test, batch_size=BATCH_SIZE[2], shuffle=False, **loader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd00e380308053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Epoch Count & Learning Rate\n",
    "EPOCHS = 2000\n",
    "LEARNING_RATE = 1e-4, 1e-6\n",
    "WEIGHT_DECAY = 0.05\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE[0], weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=LEARNING_RATE[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7fd351c87211b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length, valid_length = map(len, (train_loader, valid_loader))\n",
    "\n",
    "try:\n",
    "    epochs = tqdm(range(EPOCHS), desc=\"Running Epochs\")\n",
    "    with (tqdm(total=train_length, desc=\"Training\") as train_progress,\n",
    "        tqdm(total=valid_length, desc=\"Validation\") as valid_progress):  # Set up Progress Bars\n",
    "\n",
    "        for epoch in epochs:\n",
    "            train_progress.reset(total=train_length)\n",
    "            valid_progress.reset(total=valid_length)\n",
    "\n",
    "            train_acc, train_loss, val_acc, val_loss = [], [], [], []\n",
    "\n",
    "            # Training\n",
    "            model.train()\n",
    "            for i, (inputs, targets) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                outputs.loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                train_loss.append(outputs.loss.item())\n",
    "                train_acc.append((torch.argmax(outputs.logits, dim=1) == targets.data).sum().item() / len(inputs))\n",
    "\n",
    "                train_progress.update(1)\n",
    "                print(f\"\\rEpoch [{epoch+1:4}/{EPOCHS:4}], Step [{i+1:4}/{train_length:4}], Acc: {avg(train_acc):.6%}, Loss: {avg(train_loss):.6f}\", end=\"\")\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in valid_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = model(inputs)  # but not use model loss\n",
    "\n",
    "                    val_loss.append(outputs.loss.item())\n",
    "                    val_acc.append((torch.argmax(outputs.logits, dim=1) == targets.data).sum().item() / len(inputs))\n",
    "                    valid_progress.update(1)\n",
    "\n",
    "            print(f\"\\rEpoch [{epoch+1:4}/{EPOCHS:4}], Step [{train_length:4}/{train_length:4}], Acc: {avg(train_acc):.6%}, Loss: {avg(train_loss):.6f}, Valid Acc: {avg(val_acc):.6%}, Valid Loss: {avg(val_loss):.6f}\", end=\"\\n\" if (epoch+1) % 5 == 0 or (epoch+1) == EPOCHS else \"\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nINFO: Training interrupted by user. Saving model...\")\n",
    "finally:\n",
    "    # Model Save\n",
    "    save_directory = model.save_pretrained()  # Save to \"./results/\"\n",
    "    processor.save_pretrained(save_directory)  # Save processor config to the same directory\n",
    "    print(f\"INFO: Model saved successfully at {save_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7762d126105c4809",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a4c75ebeb969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = TargetModel.from_pretrained(save_directory, num_classes=num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf5249a208f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrects = 0\n",
    "total = len(ChosenDataset.test)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in tqdm(test_loader, desc=f\"Evaluating {ChosenDataset.dataset_name}\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        logits = outputs.logits if hasattr(outputs, \"logits\") else outputs\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        corrects += (preds == targets).sum().item()\n",
    "\n",
    "acc = corrects / total\n",
    "print(f\"\\n\" + \"=\"*40)\n",
    "print(f\"Accuracy: {acc:.6%} ({corrects}/{total})\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256aa0be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
