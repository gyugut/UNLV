"""
gradient_inversion.py
=====================
inversefed ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í•µì‹¬ ê³µê²© ë¡œì§ì„ ë¶„ì„í•˜ì—¬ ì¬êµ¬í˜„í•œ ëª¨ë“ˆ.
ì™¸ë¶€ ì˜ì¡´ì„± ì—†ì´ PyTorchë§Œìœ¼ë¡œ ë™ì‘í•˜ë©°, ì–´ë–¤ ëª¨ë¸ì´ë“  (CNN, Transformer) ì‚¬ìš© ê°€ëŠ¥.

ì›ë³¸: https://github.com/JonasGeiping/invertinggradients
ë…¼ë¬¸: Geiping et al., "Inverting Gradients", NeurIPS 2020

ì¬í˜„ ëŒ€ìƒ ë…¼ë¬¸ ì„¤ì •:
  Zhang et al., "How Does a Deep Learning Model Architecture Impact Its Privacy?"
  - cost_fn: cosine similarity
  - optimizer: Adam
  - lr: 0.1, lr_decay: True
  - max_iterations: 3000
  - total_variation: 1e-4
  - signed gradients: True
  - boxed constraint: True
"""

import torch
import torch.nn.functional as F
import math
from typing import List, Tuple, Dict, Optional


# =============================================================================
# 1. ë°ì´í„°ì…‹ ì„¤ì • (Dataset Configs)
# =============================================================================
# inversefed.constsì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„

DATASET_CONFIGS = {
    'cifar10': {
        'mean': (0.4914, 0.4822, 0.4465),
        'std':  (0.2023, 0.1994, 0.2010),
        'img_shape': (3, 32, 32),
        'num_classes': 10,
    },
    'imagenet': {
        'mean': (0.485, 0.456, 0.406),
        'std':  (0.229, 0.224, 0.225),
        'img_shape': (3, 224, 224),
        'num_classes': 1000,
    },
}

# 1ë²ˆ ë…¼ë¬¸ Table 1ì˜ ê³µê²© í•˜ì´í¼íŒŒë¼ë¯¸í„°
DEFAULT_ATTACK_CONFIG = {
    'cost_fn':         'sim',     # cosine similarity (inversefedì˜ 'sim')
    'optimizer':       'adam',    # Adam optimizer
    'lr':              0.1,       # í•™ìŠµë¥ 
    'lr_decay':        True,      # í•™ìŠµë¥  ê°ì‡  ì—¬ë¶€
    'max_iterations':  3000,      # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
    'total_variation': 1e-4,      # TV ì •ê·œí™” ê°€ì¤‘ì¹˜
    'signed':          False,      # signed gradient ì‚¬ìš© (adversarial attack ê¸°ë²•)
    'boxed':           True,      # ìœ íš¨ ë²”ìœ„ ë‚´ë¡œ í´ë¨í•‘
    'restarts':        1,         # ì¬ì‹œì‘ íšŸìˆ˜
    'init':            'randn',   # ì´ˆê¸°í™” ë°©ë²•: 'randn' ë˜ëŠ” 'rand'
}


# =============================================================================
# 2. ë¹„ìš© í•¨ìˆ˜ (Cost Functions)
# =============================================================================
# inversefed/reconstruction_algorithms.pyì˜ reconstruction_costs() ì— í•´ë‹¹

def cost_fn_cosine_sim(trial_gradients: List[torch.Tensor],
                       target_gradients: List[torch.Tensor]) -> torch.Tensor:
    """
    Cosine similarity ê¸°ë°˜ ë¹„ìš© í•¨ìˆ˜.

    inversefed ì›ë³¸ êµ¬í˜„ ë¶„ì„:
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ì›ë³¸ì€ per-layerê°€ ì•„ë‹Œ **ì „ì²´ gradientë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë³´ê³ ** cosine similarityë¥¼ ê³„ì‚°.
    êµ¬ì²´ì ìœ¼ë¡œ:
        dot_product = sum(trial[i] * target[i] for all layers)
        norm_trial  = sqrt(sum(trial[i]^2 for all layers))
        norm_target = sqrt(sum(target[i]^2 for all layers))
        cost = 1 - dot_product / (norm_trial * norm_target)

    ì´ëŠ” ëª¨ë“  gradientë¥¼ flatten â†’ concat â†’ cosine_similarity í•˜ëŠ” ê²ƒê³¼ ë™ì¼.

    Returns:
        cost: 0ì´ë©´ ì™„ë²½íˆ ì¼ì¹˜, 2ì´ë©´ ì •ë°˜ëŒ€ ë°©í–¥
    """
    dot_product = torch.tensor(0.0, device=trial_gradients[0].device)
    norm_trial_sq = torch.tensor(0.0, device=trial_gradients[0].device)
    norm_target_sq = torch.tensor(0.0, device=trial_gradients[0].device)

    for tg, ig in zip(trial_gradients, target_gradients):
        dot_product += (tg * ig).sum()
        norm_trial_sq += tg.pow(2).sum()
        norm_target_sq += ig.pow(2).sum()

    cost = 1.0 - dot_product / (norm_trial_sq.sqrt() * norm_target_sq.sqrt() + 1e-12)
    return cost


def cost_fn_l2(trial_gradients: List[torch.Tensor],
               target_gradients: List[torch.Tensor]) -> torch.Tensor:
    """
    L2 (Euclidean) ë¹„ìš© í•¨ìˆ˜. DLG/iDLG ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ ì›ë³¸ ë°©ì‹.
    ë¹„êµ ì‹¤í—˜ìš©ìœ¼ë¡œ í¬í•¨.
    """
    cost = torch.tensor(0.0, device=trial_gradients[0].device)
    for tg, ig in zip(trial_gradients, target_gradients):
        cost += (tg - ig).pow(2).sum()
    return cost


COST_FUNCTIONS = {
    'sim': cost_fn_cosine_sim,
    'l2':  cost_fn_l2,
}


# =============================================================================
# 3. ì •ê·œí™” (Regularization)
# =============================================================================
# inversefedì—ì„œ total_variationìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë¶€ë¶„

def total_variation1(x: torch.Tensor) -> torch.Tensor:
    """
    Total Variation ì •ê·œí™”.
    ì´ë¯¸ì§€ì˜ ì¸ì ‘ í”½ì…€ ê°„ ì°¨ì´ë¥¼ ìµœì†Œí™”í•˜ì—¬ ë…¸ì´ì¦ˆë¥¼ ì–µì œ.

    inversefed ì›ë³¸:
        TV(x) = sum(|x[..., i+1, j] - x[..., i, j]|^2)
              + sum(|x[..., i, j+1] - x[..., i, j]|^2)

    Args:
        x: (B, C, H, W) í…ì„œ
    Returns:
        ìŠ¤ì¹¼ë¼ TV ê°’
    """
    dx = x[:, :, 1:, :] - x[:, :, :-1, :]  # ì„¸ë¡œ ë°©í–¥ ì°¨ì´
    dy = x[:, :, :, 1:] - x[:, :, :, :-1]  # ê°€ë¡œ ë°©í–¥ ì°¨ì´
    return dx.pow(2).sum() + dy.pow(2).sum()

def total_variation(x: torch.Tensor) -> torch.Tensor:
    """Original inversefed implementation (L1 + mean)."""
    dx = torch.mean(torch.abs(x[:, :, :, :-1] - x[:, :, :, 1:]))
    dy = torch.mean(torch.abs(x[:, :, :-1, :] - x[:, :, 1:, :]))
    return dx + dy


# =============================================================================
# 4. Gradient ì¶”ì¶œ (Gradient Extraction)
# =============================================================================

def extract_gradients(model: torch.nn.Module,
                      images: torch.Tensor,
                      labels: torch.Tensor,
                      loss_fn: torch.nn.Module = None) -> List[torch.Tensor]:
    """
    ëª¨ë¸ì— ì´ë¯¸ì§€ë¥¼ ì…ë ¥í•˜ê³ , lossì— ëŒ€í•œ íŒŒë¼ë¯¸í„° gradientë¥¼ ì¶”ì¶œ.
    ì„œë²„ê°€ ë°›ëŠ” gradientì— í•´ë‹¹.

    Args:
        model:  victim ëª¨ë¸ (eval ëª¨ë“œ)
        images: (B, C, H, W) ì…ë ¥ ì´ë¯¸ì§€
        labels: (B,) ì •ë‹µ ë¼ë²¨
        loss_fn: ì†ì‹¤ í•¨ìˆ˜ (ê¸°ë³¸: CrossEntropyLoss)
    Returns:
        gradient ë¦¬ìŠ¤íŠ¸ (ê° íŒŒë¼ë¯¸í„°ì— ëŒ€ì‘)
    """
    if loss_fn is None:
        loss_fn = torch.nn.CrossEntropyLoss()

    model.zero_grad()
    output = model(images)
    loss = loss_fn(output, labels)
    gradients = torch.autograd.grad(loss, model.parameters())
    return [g.detach().clone() for g in gradients]


# =============================================================================
# 5. í•µì‹¬ ê³µê²© ë£¨í”„ (Gradient Inversion Attack)
# =============================================================================
# inversefed/reconstruction_algorithms.pyì˜ GradientReconstructor ì— í•´ë‹¹

class GradientInversionAttack:
    """
    Gradient Inversion Attack êµ¬í˜„ì²´.

    inversefed.GradientReconstructorë¥¼ ë¶„ì„í•˜ì—¬ ì¬êµ¬í˜„.
    ì–´ë–¤ PyTorch ëª¨ë¸ì´ë“  (CNN, Transformer ë“±) ë™ì‘.

    ì‚¬ìš©ë²•:
        attack = GradientInversionAttack(model, dataset='imagenet', config={...})
        reconstructed, stats = attack.reconstruct(target_gradients, labels)
    """

    def __init__(self,
                 model: torch.nn.Module,
                 dataset: str = 'imagenet',
                 config: dict = None,
                 device: torch.device = None):
        """
        Args:
            model:   ê³µê²© ëŒ€ìƒ ëª¨ë¸ (eval ëª¨ë“œì—¬ì•¼ í•¨)
            dataset: 'cifar10' ë˜ëŠ” 'imagenet' (ì •ê·œí™” ìƒìˆ˜ ê²°ì •)
            config:  ê³µê²© í•˜ì´í¼íŒŒë¼ë¯¸í„° (Noneì´ë©´ ë…¼ë¬¸ ê¸°ë³¸ê°’ ì‚¬ìš©)
            device:  ì—°ì‚° ì¥ì¹˜
        """
        self.model = model
        self.model.eval()

        # ì„¤ì • ë³‘í•© (ì‚¬ìš©ì ì§€ì • > ê¸°ë³¸ê°’)
        self.config = {**DEFAULT_ATTACK_CONFIG}
        if config is not None:
            self.config.update(config)

        # ì¥ì¹˜ ì„¤ì •
        if device is None:
            self.device = next(model.parameters()).device
        else:
            self.device = device

        # ë°ì´í„°ì…‹ ì •ê·œí™” ìƒìˆ˜
        ds_config = DATASET_CONFIGS[dataset]
        self.dm = torch.tensor(ds_config['mean'], device=self.device).view(1, 3, 1, 1)
        self.ds = torch.tensor(ds_config['std'], device=self.device).view(1, 3, 1, 1)
        self.img_shape = ds_config['img_shape']

        # ë¹„ìš© í•¨ìˆ˜
        self.cost_fn = COST_FUNCTIONS[self.config['cost_fn']]

        # ì†ì‹¤ í•¨ìˆ˜
        self.loss_fn = torch.nn.CrossEntropyLoss()

    def _initialize_dummy(self, num_images: int = 1) -> torch.Tensor:
        """
        ë”ë¯¸ ì´ë¯¸ì§€ ì´ˆê¸°í™”.

        inversefed ë¶„ì„:
        - 'randn': í‘œì¤€ ì •ê·œë¶„í¬ (ë…¼ë¬¸ ê¸°ë³¸ê°’)
        - 'rand':  [0, 1] ê· ì¼ë¶„í¬
        - boxed=Trueì¼ ë•Œ, ë‚˜ì¤‘ì— ìœ íš¨ ë²”ìœ„ë¡œ í´ë¨í•‘
        """
        shape = (num_images, *self.img_shape)

        if self.config['init'] == 'randn':
            dummy = torch.randn(shape, device=self.device, requires_grad=True)
        elif self.config['init'] == 'rand':
            dummy = torch.rand(shape, device=self.device, requires_grad=True)
        else:
            dummy = torch.randn(shape, device=self.device, requires_grad=True)

        return dummy

    def _get_valid_bounds(self) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        boxed constraintë¥¼ ìœ„í•œ ìœ íš¨ ë²”ìœ„ ê³„ì‚°.

        inversefed ë¶„ì„:
        ì›ë³¸ ì´ë¯¸ì§€ ë²”ìœ„ [0, 1]ì„ ì •ê·œí™” ê³µê°„ìœ¼ë¡œ ë³€í™˜:
          lower = (0 - mean) / std
          upper = (1 - mean) / std
        ì´ ë²”ìœ„ ë°–ì˜ ê°’ì€ ì‹¤ì œ ì´ë¯¸ì§€ì—ì„œ ë¶ˆê°€ëŠ¥í•œ ê°’ì´ë¯€ë¡œ í´ë¨í•‘.
        """
        lower = (0.0 - self.dm) / self.ds  # ì •ê·œí™” ê³µê°„ì—ì„œì˜ ìµœì†Œê°’
        upper = (1.0 - self.dm) / self.ds  # ì •ê·œí™” ê³µê°„ì—ì„œì˜ ìµœëŒ€ê°’
        return lower, upper

    def reconstruct(self,
                    target_gradients: List[torch.Tensor],
                    labels: torch.Tensor,
                    num_images: int = 1,
                    img_shape: Tuple[int, ...] = None
                    ) -> Tuple[torch.Tensor, Dict]:
        """
        Gradient Inversion ê³µê²© ì‹¤í–‰.

        inversefed.GradientReconstructor.reconstruct()ë¥¼ ì¬êµ¬í˜„.

        í•µì‹¬ ì•Œê³ ë¦¬ì¦˜:
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        1. ë”ë¯¸ ì´ë¯¸ì§€ xë¥¼ ëœë¤ ì´ˆê¸°í™”
        2. ë°˜ë³µ:
           a) xë¥¼ ëª¨ë¸ì— í†µê³¼ â†’ dummy gradient ê³„ì‚°
           b) cost = cosine_similarity_cost(dummy_grad, target_grad)
           c) cost += TV_weight * TV(x)
           d) costë¥¼ xì— ëŒ€í•´ ë¯¸ë¶„ (2ì°¨ ë¯¸ë¶„ í•„ìš”)
           e) signed gradientë¡œ x ì—…ë°ì´íŠ¸ (adversarial attack ê¸°ë²•)
           f) xë¥¼ ìœ íš¨ ë²”ìœ„ë¡œ í´ë¨í•‘ (boxed constraint)
        3. ì—¬ëŸ¬ ë²ˆ ì¬ì‹œì‘í•˜ì—¬ ìµœì  ê²°ê³¼ ì„ íƒ

        Args:
            target_gradients: ì„œë²„ê°€ ìˆ˜ì‹ í•œ gradient (ê³µê²© ì¬ë£Œ)
            labels: ì •ë‹µ ë¼ë²¨ (iDLGë¡œ ë³µì› ê°€ëŠ¥í•˜ë¯€ë¡œ known ê°€ì •)
            num_images: ë³µì›í•  ì´ë¯¸ì§€ ìˆ˜ (ê¸°ë³¸ 1)
            img_shape: ì´ë¯¸ì§€ í˜•íƒœ (Noneì´ë©´ ë°ì´í„°ì…‹ ê¸°ë³¸ê°’)
        Returns:
            (ë³µì›ëœ ì´ë¯¸ì§€, í†µê³„ ë”•ì…”ë„ˆë¦¬)
        """
        if img_shape is not None:
            self.img_shape = img_shape

        cfg = self.config
        best_cost = float('inf')
        best_result = None

        for restart_idx in range(cfg['restarts']):
            # â”€â”€â”€ ì´ˆê¸°í™” â”€â”€â”€
            x = self._initialize_dummy(num_images)
            # ë°•ìŠ¤ ë¯¸ë¦¬ ê³„ì‚°
            lower, upper = self._get_valid_bounds()

            # â”€â”€â”€ Optimizer ì„¤ì • â”€â”€â”€
            # inversefed: Adam with lr, but actual update uses signed gradient
            optimizer = torch.optim.Adam([x], lr=cfg['lr'])

            # â”€â”€â”€ LR Scheduler â”€â”€â”€
            # inversefed: MultiStepLR, milestones at [max_iter*0.5, max_iter*0.75, ...]
            if cfg['lr_decay']:
                max_iter = cfg['max_iterations']
                scheduler = torch.optim.lr_scheduler.MultiStepLR(
                    optimizer,
                    milestones=[
                        max_iter // 2.667,
                        max_iter // 1.6,
                        max_iter // 1.142,
                    ],
                    gamma=0.1
                )
            else:
                scheduler = None

            # â”€â”€â”€ ê³µê²© ë£¨í”„ â”€â”€â”€
            history = []
            for iteration in range(cfg['max_iterations']):

                # --- (a) Closure: dummy gradient ê³„ì‚° + cost ê³„ì‚° ---
                # inversefedëŠ” closure íŒ¨í„´ì„ ì‚¬ìš©í•˜ì§€ë§Œ,
                # Adam + signed gradient ì¡°í•©ì´ë¼ ì§ì ‘ backward í˜¸ì¶œì´ ë” ëª…í™•í•¨

                optimizer.zero_grad()
                self.model.zero_grad()

                # ë”ë¯¸ ì´ë¯¸ì§€ â†’ ëª¨ë¸ â†’ loss â†’ dummy gradient
                dummy_output = self.model(x)
                dummy_loss = self.loss_fn(dummy_output, labels)

                # create_graph=True: xì— ëŒ€í•œ 2ì°¨ ë¯¸ë¶„ì„ ê°€ëŠ¥í•˜ê²Œ í•¨
                # ì´ê²ƒì´ "double backpropagation"
                dummy_gradients = torch.autograd.grad(
                    dummy_loss,
                    self.model.parameters(),
                    create_graph=True
                )

                # --- (b) ë¹„ìš© í•¨ìˆ˜ ê³„ì‚° ---
                rec_cost = self.cost_fn(dummy_gradients, target_gradients)

                # --- (c) TV ì •ê·œí™” ì¶”ê°€ ---
                if cfg['total_variation'] > 0:
                    rec_cost = rec_cost + cfg['total_variation'] * total_variation(x)

                # --- (d) xì— ëŒ€í•œ gradient ê³„ì‚° ---
                rec_cost.backward()

                # --- (e) Signed gradient ì ìš© ---
                # inversefed ë¶„ì„:
                # Adamì´ momentumì„ ê´€ë¦¬í•˜ì§€ë§Œ, x.gradë¥¼ sign()ìœ¼ë¡œ ëŒ€ì²´.
                # ì´ëŠ” FGSM/PGD ìŠ¤íƒ€ì¼ì˜ adversarial attackì—ì„œ ì˜ê°ì„ ë°›ì€ ê²ƒ.
                # sign()ì€ Adamì˜ 1st/2nd momentì—ë§Œ ì˜í–¥ì„ ì£¼ê³ ,
                # ì‹¤ì œ ì—…ë°ì´íŠ¸ëŠ” accumulated momentum ê¸°ë°˜ì´ë¯€ë¡œ ìˆ˜ë ´ ê°€ëŠ¥.
                if cfg['signed']:
                    x.grad.sign_()

                optimizer.step()

                # LR ê°ì‡ 
                scheduler.step()

                # --- (f) Boxed constraint ---
                # inversefed: ì •ê·œí™” ê³µê°„ì—ì„œì˜ ìœ íš¨ ë²”ìœ„ë¡œ í´ë¨í•‘
                if cfg['boxed']:
                    with torch.no_grad():
                        x.clamp_(lower, upper)

                # --- ë¡œê¹… ---
                current_cost = rec_cost.item()
                history.append(current_cost)

                if iteration % 500 == 0 or iteration == cfg['max_iterations'] - 1:
                    print(f"  [Restart {restart_idx+1}/{cfg['restarts']}] "
                          f"Iter {iteration:5d}/{cfg['max_iterations']} | "
                          f"Cost: {current_cost:.6f}")

            # â”€â”€â”€ ìµœì  ê²°ê³¼ ì„ íƒ â”€â”€â”€
            final_cost = history[-1]
            if final_cost < best_cost:
                best_cost = final_cost
                best_result = x.detach().clone()
                best_history = history

        stats = {
            'final_cost': best_cost,
            'history': best_history,
        }

        return best_result, stats


# =============================================================================
# 6. í‰ê°€ ì§€í‘œ (Evaluation Metrics)
# =============================================================================
# 1ë²ˆ ë…¼ë¬¸ Table 5 ê¸°ì¤€: MSE, PSNR, LPIPS, SSIM

def denormalize(tensor: torch.Tensor,
                mean: torch.Tensor,
                std: torch.Tensor) -> torch.Tensor:
    """ì •ê·œí™”ëœ í…ì„œë¥¼ [0, 1] ë²”ìœ„ë¡œ ì—­ë³€í™˜."""
    return torch.clamp(tensor.detach().clone() * std + mean, 0.0, 1.0)


def compute_mse(reconstructed: torch.Tensor,
                original: torch.Tensor,
                mean: torch.Tensor,
                std: torch.Tensor) -> float:
    """
    Mean Squared Error (â†“ = ê³µê²© ì„±ê³µ).
    denormalize í›„ [0, 1] ë²”ìœ„ì—ì„œ ê³„ì‚°.
    """
    rec = denormalize(reconstructed, mean, std)
    ori = denormalize(original, mean, std)
    return (rec - ori).pow(2).mean().item()


def compute_psnr(reconstructed: torch.Tensor,
                 original: torch.Tensor,
                 mean: torch.Tensor,
                 std: torch.Tensor) -> float:
    """
    Peak Signal-to-Noise Ratio (â†‘ = ê³µê²© ì„±ê³µ).
    PSNR = 20 * log10(MAX / sqrt(MSE)), MAX=1.0
    """
    mse = compute_mse(reconstructed, original, mean, std)
    if mse == 0:
        return float('inf')
    return 20.0 * math.log10(1.0 / math.sqrt(mse))


def compute_ssim(reconstructed: torch.Tensor,
                 original: torch.Tensor,
                 mean: torch.Tensor,
                 std: torch.Tensor) -> float:
    """
    Structural Similarity Index (â†‘ = ê³µê²© ì„±ê³µ).
    ê°„ì´ êµ¬í˜„ (window_size=11, ê°€ìš°ì‹œì•ˆ ê°€ì¤‘ì¹˜).
    ì •í™•í•œ ì¬í˜„ì„ ìœ„í•´ì„œëŠ” pytorch-msssim íŒ¨í‚¤ì§€ ì‚¬ìš©ì„ ê¶Œì¥.
    """
    try:
        from pytorch_msssim import ssim as ssim_fn
        rec = denormalize(reconstructed, mean, std)
        ori = denormalize(original, mean, std)
        return ssim_fn(rec, ori, data_range=1.0, size_average=True).item()
    except ImportError:
        # Fallback: ê°„ì´ SSIM êµ¬í˜„
        rec = denormalize(reconstructed, mean, std)
        ori = denormalize(original, mean, std)
        return _simple_ssim(rec, ori)


def _simple_ssim(img1: torch.Tensor, img2: torch.Tensor,
                 window_size: int = 11) -> float:
    """ê°„ì´ SSIM (pytorch-msssim ì—†ì„ ë•Œ ì‚¬ìš©)."""
    C1 = 0.01 ** 2
    C2 = 0.03 ** 2

    mu1 = F.avg_pool2d(img1, window_size, stride=1, padding=window_size // 2)
    mu2 = F.avg_pool2d(img2, window_size, stride=1, padding=window_size // 2)

    mu1_sq = mu1.pow(2)
    mu2_sq = mu2.pow(2)
    mu1_mu2 = mu1 * mu2

    sigma1_sq = F.avg_pool2d(img1 * img1, window_size, stride=1,
                             padding=window_size // 2) - mu1_sq
    sigma2_sq = F.avg_pool2d(img2 * img2, window_size, stride=1,
                             padding=window_size // 2) - mu2_sq
    sigma12 = F.avg_pool2d(img1 * img2, window_size, stride=1,
                           padding=window_size // 2) - mu1_mu2

    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / \
               ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))

    return ssim_map.mean().item()


def compute_lpips(reconstructed: torch.Tensor,
                  original: torch.Tensor,
                  mean: torch.Tensor,
                  std: torch.Tensor,
                  lpips_model=None) -> float:
    """
    Learned Perceptual Image Patch Similarity (â†“ = ê³µê²© ì„±ê³µ).
    lpips íŒ¨í‚¤ì§€ í•„ìš”: pip install lpips

    Args:
        lpips_model: ë¯¸ë¦¬ ë¡œë“œí•œ lpips.LPIPS ê°ì²´ (Noneì´ë©´ ìƒˆë¡œ ìƒì„±)
    """
    try:
        import lpips
        if lpips_model is None:
            lpips_model = lpips.LPIPS(net='alex').to(reconstructed.device)
            lpips_model.eval()

        # LPIPSëŠ” [-1, 1] ë²”ìœ„ ì…ë ¥ì„ ê¸°ëŒ€
        rec = denormalize(reconstructed, mean, std) * 2.0 - 1.0
        ori = denormalize(original, mean, std) * 2.0 - 1.0

        with torch.no_grad():
            score = lpips_model(rec, ori)
        return score.item()
    except ImportError:
        print("âš ï¸ lpips íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. pip install lpips ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        return float('nan')


def compute_all_metrics(reconstructed: torch.Tensor,
                        original: torch.Tensor,
                        mean: torch.Tensor,
                        std: torch.Tensor,
                        lpips_model=None) -> Dict[str, float]:
    """
    1ë²ˆ ë…¼ë¬¸ Table 5 ê¸°ì¤€ 4ê°€ì§€ ì§€í‘œë¥¼ í•œ ë²ˆì— ê³„ì‚°.

    Returns:
        {'mse': ..., 'psnr': ..., 'lpips': ..., 'ssim': ...}
    """
    metrics = {
        'mse':   compute_mse(reconstructed, original, mean, std),
        'psnr':  compute_psnr(reconstructed, original, mean, std),
        'ssim':  compute_ssim(reconstructed, original, mean, std),
        'lpips': compute_lpips(reconstructed, original, mean, std, lpips_model),
    }
    return metrics


# =============================================================================
# 7. ì‹œê°í™” (Visualization)
# =============================================================================

def visualize_result(original: torch.Tensor,
                     reconstructed: torch.Tensor,
                     mean: torch.Tensor,
                     std: torch.Tensor,
                     metrics: Dict[str, float] = None,
                     save_path: str = None):
    """
    ì›ë³¸ê³¼ ë³µì› ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ ì‹œê°í™”.
    """
    import matplotlib.pyplot as plt

    ori = denormalize(original, mean, std)
    rec = denormalize(reconstructed, mean, std)

    fig, axes = plt.subplots(1, 2, figsize=(10, 5))

    axes[0].imshow(ori[0].permute(1, 2, 0).cpu().numpy())
    axes[0].set_title("Original (Ground Truth)")
    axes[0].axis('off')

    title = "Reconstructed"
    if metrics:
        title += (f"\nMSE: {metrics['mse']:.4f} | "
                  f"PSNR: {metrics['psnr']:.2f} dB\n"
                  f"SSIM: {metrics['ssim']:.4f} | "
                  f"LPIPS: {metrics['lpips']:.4f}")
    axes[1].imshow(rec[0].permute(1, 2, 0).cpu().numpy())
    axes[1].set_title(title, fontsize=10)
    axes[1].axis('off')

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {save_path}")

    plt.show()


def plot_cost_history(history: list, save_path: str = None):
    """ê³µê²© ê³¼ì •ì˜ cost ë³€í™”ë¥¼ ì‹œê°í™”."""
    import matplotlib.pyplot as plt

    plt.figure(figsize=(8, 4))
    plt.semilogy(history)
    plt.xlabel('Iteration')
    plt.ylabel('Reconstruction Cost (log scale)')
    plt.title('Attack Convergence')
    plt.grid(True, alpha=0.3)

    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')

    plt.show()


# =============================================================================
# 8. í¸ì˜ í•¨ìˆ˜ (High-Level API)
# =============================================================================

def run_attack(model: torch.nn.Module,
               image: torch.Tensor,
               label: torch.Tensor,
               dataset: str = 'imagenet',
               config: dict = None,
               verbose: bool = True) -> Tuple[torch.Tensor, Dict, Dict]:
    """
    í•œ ì¤„ë¡œ ê³µê²©ì„ ì‹¤í–‰í•˜ëŠ” í¸ì˜ í•¨ìˆ˜.

    ì‚¬ìš©ë²•:
        reconstructed, metrics, stats = run_attack(model, image, label, 'cifar10')

    Args:
        model:   victim ëª¨ë¸
        image:   (1, C, H, W) ì •ê·œí™”ëœ ì…ë ¥ ì´ë¯¸ì§€
        label:   (1,) ì •ë‹µ ë¼ë²¨
        dataset: 'cifar10' ë˜ëŠ” 'imagenet'
        config:  ê³µê²© ì„¤ì • (Noneì´ë©´ ë…¼ë¬¸ ê¸°ë³¸ê°’)
        verbose: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€
    Returns:
        (ë³µì› ì´ë¯¸ì§€, í‰ê°€ ì§€í‘œ, ê³µê²© í†µê³„)
    """
    # 1. Gradient ì¶”ì¶œ (ì„œë²„ê°€ ë°›ëŠ” ê²ƒ)
    target_gradients = extract_gradients(model, image, label)
    if verbose:
        grad_norm = torch.stack([g.norm() for g in target_gradients]).mean()
        print(f"ğŸ“Š Gradient norm: {grad_norm:.4e}")

    # 2. ê³µê²© ì‹¤í–‰
    attack = GradientInversionAttack(model, dataset=dataset, config=config)
    reconstructed, stats = attack.reconstruct(
        target_gradients, label,
        num_images=image.shape[0],
        img_shape=tuple(image.shape[1:])
    )

    # 3. í‰ê°€
    metrics = compute_all_metrics(reconstructed, image, attack.dm, attack.ds)
    if verbose:
        print(f"\nğŸ“ˆ í‰ê°€ ê²°ê³¼:")
        print(f"   MSE:   {metrics['mse']:.6f} (â†“)")
        print(f"   PSNR:  {metrics['psnr']:.2f} dB (â†‘)")
        print(f"   SSIM:  {metrics['ssim']:.4f} (â†‘)")
        print(f"   LPIPS: {metrics['lpips']:.4f} (â†“)")

    return reconstructed, metrics, stats
