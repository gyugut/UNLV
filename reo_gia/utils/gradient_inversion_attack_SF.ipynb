{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”“ Gradient Inversion Attack on Transformers\n",
    "## inversefed ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´ ì§ì ‘ êµ¬í˜„\n",
    "\n",
    "**ì¬í˜„ ëŒ€ìƒ ë…¼ë¬¸:**\n",
    "- Zhang et al., \"How Does a Deep Learning Model Architecture Impact Its Privacy?\" (2024)\n",
    "- ê³µê²© ê¸°ë°˜: Geiping et al., \"Inverting Gradients\", NeurIPS 2020\n",
    "\n",
    "**ì‹¤í—˜ ì„¤ì •:**\n",
    "- ëª¨ë¸: Swin-T, Swin-S (Transformer)\n",
    "- ë°ì´í„°ì…‹: CIFAR-10 (32Ã—32), ImageNet1K (224Ã—224)\n",
    "- ê³µê²©: Cosine Similarity + Adam + TV Regularization\n",
    "- í‰ê°€: MSE, PSNR, LPIPS, SSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA RTX PRO 5000 Blackwell\n",
      "VRAM: 50.8 GB\n"
     ]
    }
   ],
   "source": [
    "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "# !pip install lpips pytorch-msssim timm -q\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os, sys, math\n",
    "\n",
    "# GPU í™•ì¸\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. ê³µê²© í•µì‹¬ ëª¨ë“ˆ (gradient_inversion.py)\n",
    "\n",
    "`inversefed` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ì¬êµ¬í˜„í•œ ì½”ë“œì…ë‹ˆë‹¤.\n",
    "ì•„ë˜ ì…€ì„ ì‹¤í–‰í•˜ë©´ `gradient_inversion` ëª¨ë“ˆì´ ë©”ëª¨ë¦¬ì— ë¡œë“œë©ë‹ˆë‹¤.\n",
    "\n",
    "> ì´ ì…€ì˜ ì½”ë“œë¥¼ `gradient_inversion.py`ë¡œ ì €ì¥í•˜ë©´ ë³„ë„ ëª¨ë“ˆë¡œë„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "gradient_inversion.py\n",
    "=====================\n",
    "inversefed ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í•µì‹¬ ê³µê²© ë¡œì§ì„ ë¶„ì„í•˜ì—¬ ì¬êµ¬í˜„í•œ ëª¨ë“ˆ.\n",
    "ì™¸ë¶€ ì˜ì¡´ì„± ì—†ì´ PyTorchë§Œìœ¼ë¡œ ë™ì‘í•˜ë©°, ì–´ë–¤ ëª¨ë¸ì´ë“  (CNN, Transformer) ì‚¬ìš© ê°€ëŠ¥.\n",
    "\n",
    "ì›ë³¸: https://github.com/JonasGeiping/invertinggradients\n",
    "ë…¼ë¬¸: Geiping et al., \"Inverting Gradients\", NeurIPS 2020\n",
    "\n",
    "ì¬í˜„ ëŒ€ìƒ ë…¼ë¬¸ ì„¤ì •:\n",
    "  Zhang et al., \"How Does a Deep Learning Model Architecture Impact Its Privacy?\"\n",
    "  - cost_fn: cosine similarity\n",
    "  - optimizer: Adam\n",
    "  - lr: 0.1, lr_decay: True\n",
    "  - max_iterations: 3000\n",
    "  - total_variation: 1e-4\n",
    "  - signed gradients: True\n",
    "  - boxed constraint: True\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 1. ë°ì´í„°ì…‹ ì„¤ì • (Dataset Configs)\n",
    "# =============================================================================\n",
    "# inversefed.constsì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„\n",
    "\n",
    "DATASET_CONFIGS = {\n",
    "    'cifar10': {\n",
    "        'mean': (0.4914, 0.4822, 0.4465),\n",
    "        'std':  (0.2023, 0.1994, 0.2010),\n",
    "        'img_shape': (3, 32, 32),\n",
    "        'num_classes': 10,\n",
    "    },\n",
    "    'imagenet': {\n",
    "        'mean': (0.485, 0.456, 0.406),\n",
    "        'std':  (0.229, 0.224, 0.225),\n",
    "        'img_shape': (3, 224, 224),\n",
    "        'num_classes': 1000,\n",
    "    },\n",
    "}\n",
    "\n",
    "# 1ë²ˆ ë…¼ë¬¸ Table 1ì˜ ê³µê²© í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "DEFAULT_ATTACK_CONFIG = {\n",
    "    'cost_fn':         'sim',     # cosine similarity (inversefedì˜ 'sim')\n",
    "    'optimizer':       'adam',    # Adam optimizer\n",
    "    'lr':              0.1,       # í•™ìŠµë¥ \n",
    "    'lr_decay':        True,      # í•™ìŠµë¥  ê°ì‡  ì—¬ë¶€\n",
    "    'max_iterations':  3000,      # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜\n",
    "    'total_variation': 1e-4,      # TV ì •ê·œí™” ê°€ì¤‘ì¹˜\n",
    "    'signed':          False,      # signed gradient ì‚¬ìš© (adversarial attack ê¸°ë²•)\n",
    "    'boxed':           True,      # ìœ íš¨ ë²”ìœ„ ë‚´ë¡œ í´ë¨í•‘\n",
    "    'restarts':        1,         # ì¬ì‹œì‘ íšŸìˆ˜\n",
    "    'init':            'randn',   # ì´ˆê¸°í™” ë°©ë²•: 'randn' ë˜ëŠ” 'rand'\n",
    "}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. ë¹„ìš© í•¨ìˆ˜ (Cost Functions)\n",
    "# =============================================================================\n",
    "# inversefed/reconstruction_algorithms.pyì˜ reconstruction_costs() ì— í•´ë‹¹\n",
    "\n",
    "def cost_fn_cosine_sim(trial_gradients: List[torch.Tensor],\n",
    "                       target_gradients: List[torch.Tensor]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Cosine similarity ê¸°ë°˜ ë¹„ìš© í•¨ìˆ˜.\n",
    "\n",
    "    inversefed ì›ë³¸ êµ¬í˜„ ë¶„ì„:\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    ì›ë³¸ì€ per-layerê°€ ì•„ë‹Œ **ì „ì²´ gradientë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë³´ê³ ** cosine similarityë¥¼ ê³„ì‚°.\n",
    "    êµ¬ì²´ì ìœ¼ë¡œ:\n",
    "        dot_product = sum(trial[i] * target[i] for all layers)\n",
    "        norm_trial  = sqrt(sum(trial[i]^2 for all layers))\n",
    "        norm_target = sqrt(sum(target[i]^2 for all layers))\n",
    "        cost = 1 - dot_product / (norm_trial * norm_target)\n",
    "\n",
    "    ì´ëŠ” ëª¨ë“  gradientë¥¼ flatten â†’ concat â†’ cosine_similarity í•˜ëŠ” ê²ƒê³¼ ë™ì¼.\n",
    "\n",
    "    Returns:\n",
    "        cost: 0ì´ë©´ ì™„ë²½íˆ ì¼ì¹˜, 2ì´ë©´ ì •ë°˜ëŒ€ ë°©í–¥\n",
    "    \"\"\"\n",
    "    dot_product = torch.tensor(0.0, device=trial_gradients[0].device)\n",
    "    norm_trial_sq = torch.tensor(0.0, device=trial_gradients[0].device)\n",
    "    norm_target_sq = torch.tensor(0.0, device=trial_gradients[0].device)\n",
    "\n",
    "    for tg, ig in zip(trial_gradients, target_gradients):\n",
    "        dot_product += (tg * ig).sum()\n",
    "        norm_trial_sq += tg.pow(2).sum()\n",
    "        norm_target_sq += ig.pow(2).sum()\n",
    "\n",
    "    cost = 1.0 - dot_product / (norm_trial_sq.sqrt() * norm_target_sq.sqrt() + 1e-12)\n",
    "    return cost\n",
    "\n",
    "\n",
    "def cost_fn_l2(trial_gradients: List[torch.Tensor],\n",
    "               target_gradients: List[torch.Tensor]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    L2 (Euclidean) ë¹„ìš© í•¨ìˆ˜. DLG/iDLG ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ ì›ë³¸ ë°©ì‹.\n",
    "    ë¹„êµ ì‹¤í—˜ìš©ìœ¼ë¡œ í¬í•¨.\n",
    "    \"\"\"\n",
    "    cost = torch.tensor(0.0, device=trial_gradients[0].device)\n",
    "    for tg, ig in zip(trial_gradients, target_gradients):\n",
    "        cost += (tg - ig).pow(2).sum()\n",
    "    return cost\n",
    "\n",
    "\n",
    "COST_FUNCTIONS = {\n",
    "    'sim': cost_fn_cosine_sim,\n",
    "    'l2':  cost_fn_l2,\n",
    "}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3. ì •ê·œí™” (Regularization)\n",
    "# =============================================================================\n",
    "# inversefedì—ì„œ total_variationìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë¶€ë¶„\n",
    "\n",
    "def total_variation1(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Total Variation ì •ê·œí™”.\n",
    "    ì´ë¯¸ì§€ì˜ ì¸ì ‘ í”½ì…€ ê°„ ì°¨ì´ë¥¼ ìµœì†Œí™”í•˜ì—¬ ë…¸ì´ì¦ˆë¥¼ ì–µì œ.\n",
    "\n",
    "    inversefed ì›ë³¸:\n",
    "        TV(x) = sum(|x[..., i+1, j] - x[..., i, j]|^2)\n",
    "              + sum(|x[..., i, j+1] - x[..., i, j]|^2)\n",
    "\n",
    "    Args:\n",
    "        x: (B, C, H, W) í…ì„œ\n",
    "    Returns:\n",
    "        ìŠ¤ì¹¼ë¼ TV ê°’\n",
    "    \"\"\"\n",
    "    dx = x[:, :, 1:, :] - x[:, :, :-1, :]  # ì„¸ë¡œ ë°©í–¥ ì°¨ì´\n",
    "    dy = x[:, :, :, 1:] - x[:, :, :, :-1]  # ê°€ë¡œ ë°©í–¥ ì°¨ì´\n",
    "    return dx.pow(2).sum() + dy.pow(2).sum()\n",
    "\n",
    "def total_variation(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Original inversefed implementation (L1 + mean).\"\"\"\n",
    "    dx = torch.mean(torch.abs(x[:, :, :, :-1] - x[:, :, :, 1:]))\n",
    "    dy = torch.mean(torch.abs(x[:, :, :-1, :] - x[:, :, 1:, :]))\n",
    "    return dx + dy\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Gradient ì¶”ì¶œ (Gradient Extraction)\n",
    "# =============================================================================\n",
    "\n",
    "def extract_gradients(model: torch.nn.Module,\n",
    "                      images: torch.Tensor,\n",
    "                      labels: torch.Tensor,\n",
    "                      loss_fn: torch.nn.Module = None) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ì— ì´ë¯¸ì§€ë¥¼ ì…ë ¥í•˜ê³ , lossì— ëŒ€í•œ íŒŒë¼ë¯¸í„° gradientë¥¼ ì¶”ì¶œ.\n",
    "    ì„œë²„ê°€ ë°›ëŠ” gradientì— í•´ë‹¹.\n",
    "\n",
    "    Args:\n",
    "        model:  victim ëª¨ë¸ (eval ëª¨ë“œ)\n",
    "        images: (B, C, H, W) ì…ë ¥ ì´ë¯¸ì§€\n",
    "        labels: (B,) ì •ë‹µ ë¼ë²¨\n",
    "        loss_fn: ì†ì‹¤ í•¨ìˆ˜ (ê¸°ë³¸: CrossEntropyLoss)\n",
    "    Returns:\n",
    "        gradient ë¦¬ìŠ¤íŠ¸ (ê° íŒŒë¼ë¯¸í„°ì— ëŒ€ì‘)\n",
    "    \"\"\"\n",
    "    if loss_fn is None:\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model.zero_grad()\n",
    "    output = model(images)\n",
    "    loss = loss_fn(output, labels)\n",
    "    gradients = torch.autograd.grad(loss, model.parameters())\n",
    "    return [g.detach().clone() for g in gradients]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5. í•µì‹¬ ê³µê²© ë£¨í”„ (Gradient Inversion Attack)\n",
    "# =============================================================================\n",
    "# inversefed/reconstruction_algorithms.pyì˜ GradientReconstructor ì— í•´ë‹¹\n",
    "\n",
    "class GradientInversionAttack:\n",
    "    \"\"\"\n",
    "    Gradient Inversion Attack êµ¬í˜„ì²´.\n",
    "\n",
    "    inversefed.GradientReconstructorë¥¼ ë¶„ì„í•˜ì—¬ ì¬êµ¬í˜„.\n",
    "    ì–´ë–¤ PyTorch ëª¨ë¸ì´ë“  (CNN, Transformer ë“±) ë™ì‘.\n",
    "\n",
    "    ì‚¬ìš©ë²•:\n",
    "        attack = GradientInversionAttack(model, dataset='imagenet', config={...})\n",
    "        reconstructed, stats = attack.reconstruct(target_gradients, labels)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module,\n",
    "                 dataset: str = 'imagenet',\n",
    "                 config: dict = None,\n",
    "                 device: torch.device = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model:   ê³µê²© ëŒ€ìƒ ëª¨ë¸ (eval ëª¨ë“œì—¬ì•¼ í•¨)\n",
    "            dataset: 'cifar10' ë˜ëŠ” 'imagenet' (ì •ê·œí™” ìƒìˆ˜ ê²°ì •)\n",
    "            config:  ê³µê²© í•˜ì´í¼íŒŒë¼ë¯¸í„° (Noneì´ë©´ ë…¼ë¬¸ ê¸°ë³¸ê°’ ì‚¬ìš©)\n",
    "            device:  ì—°ì‚° ì¥ì¹˜\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "        # ì„¤ì • ë³‘í•© (ì‚¬ìš©ì ì§€ì • > ê¸°ë³¸ê°’)\n",
    "        self.config = {**DEFAULT_ATTACK_CONFIG}\n",
    "        if config is not None:\n",
    "            self.config.update(config)\n",
    "\n",
    "        # ì¥ì¹˜ ì„¤ì •\n",
    "        if device is None:\n",
    "            self.device = next(model.parameters()).device\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        # ë°ì´í„°ì…‹ ì •ê·œí™” ìƒìˆ˜\n",
    "        ds_config = DATASET_CONFIGS[dataset]\n",
    "        self.dm = torch.tensor(ds_config['mean'], device=self.device).view(1, 3, 1, 1)\n",
    "        self.ds = torch.tensor(ds_config['std'], device=self.device).view(1, 3, 1, 1)\n",
    "        self.img_shape = ds_config['img_shape']\n",
    "\n",
    "        # ë¹„ìš© í•¨ìˆ˜\n",
    "        self.cost_fn = COST_FUNCTIONS[self.config['cost_fn']]\n",
    "\n",
    "        # ì†ì‹¤ í•¨ìˆ˜\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def _initialize_dummy(self, num_images: int = 1) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        ë”ë¯¸ ì´ë¯¸ì§€ ì´ˆê¸°í™”.\n",
    "\n",
    "        inversefed ë¶„ì„:\n",
    "        - 'randn': í‘œì¤€ ì •ê·œë¶„í¬ (ë…¼ë¬¸ ê¸°ë³¸ê°’)\n",
    "        - 'rand':  [0, 1] ê· ì¼ë¶„í¬\n",
    "        - boxed=Trueì¼ ë•Œ, ë‚˜ì¤‘ì— ìœ íš¨ ë²”ìœ„ë¡œ í´ë¨í•‘\n",
    "        \"\"\"\n",
    "        shape = (num_images, *self.img_shape)\n",
    "\n",
    "        if self.config['init'] == 'randn':\n",
    "            dummy = torch.randn(shape, device=self.device, requires_grad=True)\n",
    "        elif self.config['init'] == 'rand':\n",
    "            dummy = torch.rand(shape, device=self.device, requires_grad=True)\n",
    "        else:\n",
    "            dummy = torch.randn(shape, device=self.device, requires_grad=True)\n",
    "\n",
    "        return dummy\n",
    "\n",
    "    def _get_valid_bounds(self) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        boxed constraintë¥¼ ìœ„í•œ ìœ íš¨ ë²”ìœ„ ê³„ì‚°.\n",
    "\n",
    "        inversefed ë¶„ì„:\n",
    "        ì›ë³¸ ì´ë¯¸ì§€ ë²”ìœ„ [0, 1]ì„ ì •ê·œí™” ê³µê°„ìœ¼ë¡œ ë³€í™˜:\n",
    "          lower = (0 - mean) / std\n",
    "          upper = (1 - mean) / std\n",
    "        ì´ ë²”ìœ„ ë°–ì˜ ê°’ì€ ì‹¤ì œ ì´ë¯¸ì§€ì—ì„œ ë¶ˆê°€ëŠ¥í•œ ê°’ì´ë¯€ë¡œ í´ë¨í•‘.\n",
    "        \"\"\"\n",
    "        lower = (0.0 - self.dm) / self.ds  # ì •ê·œí™” ê³µê°„ì—ì„œì˜ ìµœì†Œê°’\n",
    "        upper = (1.0 - self.dm) / self.ds  # ì •ê·œí™” ê³µê°„ì—ì„œì˜ ìµœëŒ€ê°’\n",
    "        return lower, upper\n",
    "\n",
    "    def reconstruct(self,\n",
    "                    target_gradients: List[torch.Tensor],\n",
    "                    labels: torch.Tensor,\n",
    "                    num_images: int = 1,\n",
    "                    img_shape: Tuple[int, ...] = None\n",
    "                    ) -> Tuple[torch.Tensor, Dict]:\n",
    "        \"\"\"\n",
    "        Gradient Inversion ê³µê²© ì‹¤í–‰.\n",
    "\n",
    "        inversefed.GradientReconstructor.reconstruct()ë¥¼ ì¬êµ¬í˜„.\n",
    "\n",
    "        í•µì‹¬ ì•Œê³ ë¦¬ì¦˜:\n",
    "        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        1. ë”ë¯¸ ì´ë¯¸ì§€ xë¥¼ ëœë¤ ì´ˆê¸°í™”\n",
    "        2. ë°˜ë³µ:\n",
    "           a) xë¥¼ ëª¨ë¸ì— í†µê³¼ â†’ dummy gradient ê³„ì‚°\n",
    "           b) cost = cosine_similarity_cost(dummy_grad, target_grad)\n",
    "           c) cost += TV_weight * TV(x)\n",
    "           d) costë¥¼ xì— ëŒ€í•´ ë¯¸ë¶„ (2ì°¨ ë¯¸ë¶„ í•„ìš”)\n",
    "           e) signed gradientë¡œ x ì—…ë°ì´íŠ¸ (adversarial attack ê¸°ë²•)\n",
    "           f) xë¥¼ ìœ íš¨ ë²”ìœ„ë¡œ í´ë¨í•‘ (boxed constraint)\n",
    "        3. ì—¬ëŸ¬ ë²ˆ ì¬ì‹œì‘í•˜ì—¬ ìµœì  ê²°ê³¼ ì„ íƒ\n",
    "\n",
    "        Args:\n",
    "            target_gradients: ì„œë²„ê°€ ìˆ˜ì‹ í•œ gradient (ê³µê²© ì¬ë£Œ)\n",
    "            labels: ì •ë‹µ ë¼ë²¨ (iDLGë¡œ ë³µì› ê°€ëŠ¥í•˜ë¯€ë¡œ known ê°€ì •)\n",
    "            num_images: ë³µì›í•  ì´ë¯¸ì§€ ìˆ˜ (ê¸°ë³¸ 1)\n",
    "            img_shape: ì´ë¯¸ì§€ í˜•íƒœ (Noneì´ë©´ ë°ì´í„°ì…‹ ê¸°ë³¸ê°’)\n",
    "        Returns:\n",
    "            (ë³µì›ëœ ì´ë¯¸ì§€, í†µê³„ ë”•ì…”ë„ˆë¦¬)\n",
    "        \"\"\"\n",
    "        if img_shape is not None:\n",
    "            self.img_shape = img_shape\n",
    "\n",
    "        cfg = self.config\n",
    "        best_cost = float('inf')\n",
    "        best_result = None\n",
    "\n",
    "        for restart_idx in range(cfg['restarts']):\n",
    "            # â”€â”€â”€ ì´ˆê¸°í™” â”€â”€â”€\n",
    "            x = self._initialize_dummy(num_images)\n",
    "            # ë°•ìŠ¤ ë¯¸ë¦¬ ê³„ì‚°\n",
    "            lower, upper = self._get_valid_bounds()\n",
    "\n",
    "            # â”€â”€â”€ Optimizer ì„¤ì • â”€â”€â”€\n",
    "            # inversefed: Adam with lr, but actual update uses signed gradient\n",
    "            optimizer = torch.optim.Adam([x], lr=cfg['lr'])\n",
    "\n",
    "            # â”€â”€â”€ LR Scheduler â”€â”€â”€\n",
    "            # inversefed: MultiStepLR, milestones at [max_iter*0.5, max_iter*0.75, ...]\n",
    "            if cfg['lr_decay']:\n",
    "                max_iter = cfg['max_iterations']\n",
    "                scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "                    optimizer,\n",
    "                    milestones=[\n",
    "                        max_iter // 2.667,\n",
    "                        max_iter // 1.6,\n",
    "                        max_iter // 1.142,\n",
    "                    ],\n",
    "                    gamma=0.1\n",
    "                )\n",
    "            else:\n",
    "                scheduler = None\n",
    "\n",
    "            # â”€â”€â”€ ê³µê²© ë£¨í”„ â”€â”€â”€\n",
    "            history = []\n",
    "            for iteration in range(cfg['max_iterations']):\n",
    "\n",
    "                # --- (a) Closure: dummy gradient ê³„ì‚° + cost ê³„ì‚° ---\n",
    "                # inversefedëŠ” closure íŒ¨í„´ì„ ì‚¬ìš©í•˜ì§€ë§Œ,\n",
    "                # Adam + signed gradient ì¡°í•©ì´ë¼ ì§ì ‘ backward í˜¸ì¶œì´ ë” ëª…í™•í•¨\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                self.model.zero_grad()\n",
    "\n",
    "                # ë”ë¯¸ ì´ë¯¸ì§€ â†’ ëª¨ë¸ â†’ loss â†’ dummy gradient\n",
    "                dummy_output = self.model(x)\n",
    "                dummy_loss = self.loss_fn(dummy_output, labels)\n",
    "\n",
    "                # create_graph=True: xì— ëŒ€í•œ 2ì°¨ ë¯¸ë¶„ì„ ê°€ëŠ¥í•˜ê²Œ í•¨\n",
    "                # ì´ê²ƒì´ \"double backpropagation\"\n",
    "                dummy_gradients = torch.autograd.grad(\n",
    "                    dummy_loss,\n",
    "                    self.model.parameters(),\n",
    "                    create_graph=True\n",
    "                )\n",
    "\n",
    "                # --- (b) ë¹„ìš© í•¨ìˆ˜ ê³„ì‚° ---\n",
    "                rec_cost = self.cost_fn(dummy_gradients, target_gradients)\n",
    "\n",
    "                # --- (c) TV ì •ê·œí™” ì¶”ê°€ ---\n",
    "                if cfg['total_variation'] > 0:\n",
    "                    rec_cost = rec_cost + cfg['total_variation'] * total_variation(x)\n",
    "\n",
    "                # --- (d) xì— ëŒ€í•œ gradient ê³„ì‚° ---\n",
    "                rec_cost.backward()\n",
    "\n",
    "                # --- (e) Signed gradient ì ìš© ---\n",
    "                # inversefed ë¶„ì„:\n",
    "                # Adamì´ momentumì„ ê´€ë¦¬í•˜ì§€ë§Œ, x.gradë¥¼ sign()ìœ¼ë¡œ ëŒ€ì²´.\n",
    "                # ì´ëŠ” FGSM/PGD ìŠ¤íƒ€ì¼ì˜ adversarial attackì—ì„œ ì˜ê°ì„ ë°›ì€ ê²ƒ.\n",
    "                # sign()ì€ Adamì˜ 1st/2nd momentì—ë§Œ ì˜í–¥ì„ ì£¼ê³ ,\n",
    "                # ì‹¤ì œ ì—…ë°ì´íŠ¸ëŠ” accumulated momentum ê¸°ë°˜ì´ë¯€ë¡œ ìˆ˜ë ´ ê°€ëŠ¥.\n",
    "                if cfg['signed']:\n",
    "                    x.grad.sign_()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                # LR ê°ì‡ \n",
    "                scheduler.step()\n",
    "\n",
    "                # --- (f) Boxed constraint ---\n",
    "                # inversefed: ì •ê·œí™” ê³µê°„ì—ì„œì˜ ìœ íš¨ ë²”ìœ„ë¡œ í´ë¨í•‘\n",
    "                if cfg['boxed']:\n",
    "                    with torch.no_grad():\n",
    "                        x.clamp_(lower, upper)\n",
    "\n",
    "                # --- ë¡œê¹… ---\n",
    "                current_cost = rec_cost.item()\n",
    "                history.append(current_cost)\n",
    "\n",
    "                if iteration % 500 == 0 or iteration == cfg['max_iterations'] - 1:\n",
    "                    print(f\"  [Restart {restart_idx+1}/{cfg['restarts']}] \"\n",
    "                          f\"Iter {iteration:5d}/{cfg['max_iterations']} | \"\n",
    "                          f\"Cost: {current_cost:.6f}\")\n",
    "\n",
    "            # â”€â”€â”€ ìµœì  ê²°ê³¼ ì„ íƒ â”€â”€â”€\n",
    "            final_cost = history[-1]\n",
    "            if final_cost < best_cost:\n",
    "                best_cost = final_cost\n",
    "                best_result = x.detach().clone()\n",
    "                best_history = history\n",
    "\n",
    "        stats = {\n",
    "            'final_cost': best_cost,\n",
    "            'history': best_history,\n",
    "        }\n",
    "\n",
    "        return best_result, stats\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 6. í‰ê°€ ì§€í‘œ (Evaluation Metrics)\n",
    "# =============================================================================\n",
    "# 1ë²ˆ ë…¼ë¬¸ Table 5 ê¸°ì¤€: MSE, PSNR, LPIPS, SSIM\n",
    "\n",
    "def denormalize(tensor: torch.Tensor,\n",
    "                mean: torch.Tensor,\n",
    "                std: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"ì •ê·œí™”ëœ í…ì„œë¥¼ [0, 1] ë²”ìœ„ë¡œ ì—­ë³€í™˜.\"\"\"\n",
    "    return torch.clamp(tensor.detach().clone() * std + mean, 0.0, 1.0)\n",
    "\n",
    "\n",
    "def compute_mse(reconstructed: torch.Tensor,\n",
    "                original: torch.Tensor,\n",
    "                mean: torch.Tensor,\n",
    "                std: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Mean Squared Error (â†“ = ê³µê²© ì„±ê³µ).\n",
    "    denormalize í›„ [0, 1] ë²”ìœ„ì—ì„œ ê³„ì‚°.\n",
    "    \"\"\"\n",
    "    rec = denormalize(reconstructed, mean, std)\n",
    "    ori = denormalize(original, mean, std)\n",
    "    return (rec - ori).pow(2).mean().item()\n",
    "\n",
    "\n",
    "def compute_psnr(reconstructed: torch.Tensor,\n",
    "                 original: torch.Tensor,\n",
    "                 mean: torch.Tensor,\n",
    "                 std: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Peak Signal-to-Noise Ratio (â†‘ = ê³µê²© ì„±ê³µ).\n",
    "    PSNR = 20 * log10(MAX / sqrt(MSE)), MAX=1.0\n",
    "    \"\"\"\n",
    "    mse = compute_mse(reconstructed, original, mean, std)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20.0 * math.log10(1.0 / math.sqrt(mse))\n",
    "\n",
    "\n",
    "def compute_ssim(reconstructed: torch.Tensor,\n",
    "                 original: torch.Tensor,\n",
    "                 mean: torch.Tensor,\n",
    "                 std: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Structural Similarity Index (â†‘ = ê³µê²© ì„±ê³µ).\n",
    "    ê°„ì´ êµ¬í˜„ (window_size=11, ê°€ìš°ì‹œì•ˆ ê°€ì¤‘ì¹˜).\n",
    "    ì •í™•í•œ ì¬í˜„ì„ ìœ„í•´ì„œëŠ” pytorch-msssim íŒ¨í‚¤ì§€ ì‚¬ìš©ì„ ê¶Œì¥.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from pytorch_msssim import ssim as ssim_fn\n",
    "        rec = denormalize(reconstructed, mean, std)\n",
    "        ori = denormalize(original, mean, std)\n",
    "        return ssim_fn(rec, ori, data_range=1.0, size_average=True).item()\n",
    "    except ImportError:\n",
    "        # Fallback: ê°„ì´ SSIM êµ¬í˜„\n",
    "        rec = denormalize(reconstructed, mean, std)\n",
    "        ori = denormalize(original, mean, std)\n",
    "        return _simple_ssim(rec, ori)\n",
    "\n",
    "\n",
    "def _simple_ssim(img1: torch.Tensor, img2: torch.Tensor,\n",
    "                 window_size: int = 11) -> float:\n",
    "    \"\"\"ê°„ì´ SSIM (pytorch-msssim ì—†ì„ ë•Œ ì‚¬ìš©).\"\"\"\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "\n",
    "    mu1 = F.avg_pool2d(img1, window_size, stride=1, padding=window_size // 2)\n",
    "    mu2 = F.avg_pool2d(img2, window_size, stride=1, padding=window_size // 2)\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.avg_pool2d(img1 * img1, window_size, stride=1,\n",
    "                             padding=window_size // 2) - mu1_sq\n",
    "    sigma2_sq = F.avg_pool2d(img2 * img2, window_size, stride=1,\n",
    "                             padding=window_size // 2) - mu2_sq\n",
    "    sigma12 = F.avg_pool2d(img1 * img2, window_size, stride=1,\n",
    "                           padding=window_size // 2) - mu1_mu2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
    "               ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    return ssim_map.mean().item()\n",
    "\n",
    "\n",
    "def compute_lpips(reconstructed: torch.Tensor,\n",
    "                  original: torch.Tensor,\n",
    "                  mean: torch.Tensor,\n",
    "                  std: torch.Tensor,\n",
    "                  lpips_model=None) -> float:\n",
    "    \"\"\"\n",
    "    Learned Perceptual Image Patch Similarity (â†“ = ê³µê²© ì„±ê³µ).\n",
    "    lpips íŒ¨í‚¤ì§€ í•„ìš”: pip install lpips\n",
    "\n",
    "    Args:\n",
    "        lpips_model: ë¯¸ë¦¬ ë¡œë“œí•œ lpips.LPIPS ê°ì²´ (Noneì´ë©´ ìƒˆë¡œ ìƒì„±)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import lpips\n",
    "        if lpips_model is None:\n",
    "            lpips_model = lpips.LPIPS(net='alex').to(reconstructed.device)\n",
    "            lpips_model.eval()\n",
    "\n",
    "        # LPIPSëŠ” [-1, 1] ë²”ìœ„ ì…ë ¥ì„ ê¸°ëŒ€\n",
    "        rec = denormalize(reconstructed, mean, std) * 2.0 - 1.0\n",
    "        ori = denormalize(original, mean, std) * 2.0 - 1.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            score = lpips_model(rec, ori)\n",
    "        return score.item()\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ lpips íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. pip install lpips ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.\")\n",
    "        return float('nan')\n",
    "\n",
    "\n",
    "def compute_all_metrics(reconstructed: torch.Tensor,\n",
    "                        original: torch.Tensor,\n",
    "                        mean: torch.Tensor,\n",
    "                        std: torch.Tensor,\n",
    "                        lpips_model=None) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    1ë²ˆ ë…¼ë¬¸ Table 5 ê¸°ì¤€ 4ê°€ì§€ ì§€í‘œë¥¼ í•œ ë²ˆì— ê³„ì‚°.\n",
    "\n",
    "    Returns:\n",
    "        {'mse': ..., 'psnr': ..., 'lpips': ..., 'ssim': ...}\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'mse':   compute_mse(reconstructed, original, mean, std),\n",
    "        'psnr':  compute_psnr(reconstructed, original, mean, std),\n",
    "        'ssim':  compute_ssim(reconstructed, original, mean, std),\n",
    "        'lpips': compute_lpips(reconstructed, original, mean, std, lpips_model),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 7. ì‹œê°í™” (Visualization)\n",
    "# =============================================================================\n",
    "\n",
    "def visualize_result(original: torch.Tensor,\n",
    "                     reconstructed: torch.Tensor,\n",
    "                     mean: torch.Tensor,\n",
    "                     std: torch.Tensor,\n",
    "                     metrics: Dict[str, float] = None,\n",
    "                     save_path: str = None):\n",
    "    \"\"\"\n",
    "    ì›ë³¸ê³¼ ë³µì› ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ ì‹œê°í™”.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    print(f\"ğŸ•µï¸ [Original] Min: {original.min():.2f}, Max: {original.max():.2f}\")\n",
    "    print(f\"ğŸ•µï¸ [Reconstructed] Min: {reconstructed.min():.2f}, Max: {reconstructed.max():.2f}\")\n",
    "\n",
    "    ori = denormalize(original, mean, std)\n",
    "    rec = denormalize(reconstructed, mean, std)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    axes[0].imshow(ori[0].permute(1, 2, 0).cpu().numpy())\n",
    "    axes[0].set_title(\"Original (Ground Truth)\")\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    title = \"Reconstructed\"\n",
    "    if metrics:\n",
    "        title += (f\"\\nMSE: {metrics['mse']:.4f} | \"\n",
    "                  f\"PSNR: {metrics['psnr']:.2f} dB\\n\"\n",
    "                  f\"SSIM: {metrics['ssim']:.4f} | \"\n",
    "                  f\"LPIPS: {metrics['lpips']:.4f}\")\n",
    "    axes[1].imshow(rec[0].permute(1, 2, 0).cpu().numpy())\n",
    "    axes[1].set_title(title, fontsize=10)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"ğŸ’¾ ê²°ê³¼ ì €ì¥: {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_cost_history(history: list, save_path: str = None):\n",
    "    \"\"\"ê³µê²© ê³¼ì •ì˜ cost ë³€í™”ë¥¼ ì‹œê°í™”.\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.semilogy(history)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Reconstruction Cost (log scale)')\n",
    "    plt.title('Attack Convergence')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8. í¸ì˜ í•¨ìˆ˜ (High-Level API)\n",
    "# =============================================================================\n",
    "\n",
    "def run_attack(model: torch.nn.Module,\n",
    "               image: torch.Tensor,\n",
    "               label: torch.Tensor,\n",
    "               dataset: str = 'imagenet',\n",
    "               config: dict = None,\n",
    "               verbose: bool = True) -> Tuple[torch.Tensor, Dict, Dict]:\n",
    "    \"\"\"\n",
    "    í•œ ì¤„ë¡œ ê³µê²©ì„ ì‹¤í–‰í•˜ëŠ” í¸ì˜ í•¨ìˆ˜.\n",
    "\n",
    "    ì‚¬ìš©ë²•:\n",
    "        reconstructed, metrics, stats = run_attack(model, image, label, 'cifar10')\n",
    "\n",
    "    Args:\n",
    "        model:   victim ëª¨ë¸\n",
    "        image:   (1, C, H, W) ì •ê·œí™”ëœ ì…ë ¥ ì´ë¯¸ì§€\n",
    "        label:   (1,) ì •ë‹µ ë¼ë²¨\n",
    "        dataset: 'cifar10' ë˜ëŠ” 'imagenet'\n",
    "        config:  ê³µê²© ì„¤ì • (Noneì´ë©´ ë…¼ë¬¸ ê¸°ë³¸ê°’)\n",
    "        verbose: ì§„í–‰ ìƒí™© ì¶œë ¥ ì—¬ë¶€\n",
    "    Returns:\n",
    "        (ë³µì› ì´ë¯¸ì§€, í‰ê°€ ì§€í‘œ, ê³µê²© í†µê³„)\n",
    "    \"\"\"\n",
    "    # 1. Gradient ì¶”ì¶œ (ì„œë²„ê°€ ë°›ëŠ” ê²ƒ)\n",
    "    target_gradients = extract_gradients(model, image, label)\n",
    "    if verbose:\n",
    "        grad_norm = torch.stack([g.norm() for g in target_gradients]).mean()\n",
    "        print(f\"ğŸ“Š Gradient norm: {grad_norm:.4e}\")\n",
    "\n",
    "    # 2. ê³µê²© ì‹¤í–‰\n",
    "    attack = GradientInversionAttack(model, dataset=dataset, config=config)\n",
    "    reconstructed, stats = attack.reconstruct(\n",
    "        target_gradients, label,\n",
    "        num_images=image.shape[0],\n",
    "        img_shape=tuple(image.shape[1:])\n",
    "    )\n",
    "\n",
    "    # 3. í‰ê°€\n",
    "    metrics = compute_all_metrics(reconstructed, image, attack.dm, attack.ds)\n",
    "    if verbose:\n",
    "        print(f\"\\nğŸ“ˆ í‰ê°€ ê²°ê³¼:\")\n",
    "        print(f\"   MSE:   {metrics['mse']:.6f} (â†“)\")\n",
    "        print(f\"   PSNR:  {metrics['psnr']:.2f} dB (â†‘)\")\n",
    "        print(f\"   SSIM:  {metrics['ssim']:.4f} (â†‘)\")\n",
    "        print(f\"   LPIPS: {metrics['lpips']:.4f} (â†“)\")\n",
    "\n",
    "    return reconstructed, metrics, stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. ê³µê²© í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "\n",
    "ë…¼ë¬¸ Table 1 ê¸°ì¤€ ì„¤ì •ê°’ì…ë‹ˆë‹¤.\n",
    "\n",
    "| í•­ëª© | ê°’ | ì„¤ëª… |\n",
    "|------|-----|------|\n",
    "| cost function | cosine similarity | inversefedì˜ `sim` |\n",
    "| optimizer | Adam | signed gradient ì‚¬ìš© |\n",
    "| learning rate | 0.1 | lr_decay ì ìš© |\n",
    "| iterations | 3000 | ë…¼ë¬¸ ê³ ì •ê°’ |\n",
    "| total variation | 0.0001 | ë…¸ì´ì¦ˆ ì–µì œ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê³µê²© ì„¤ì • ì™„ë£Œ\n",
      "   cost_fn: sim\n",
      "   optimizer: adam\n",
      "   lr: 0.1\n",
      "   lr_decay: True\n",
      "   max_iterations: 3000\n",
      "   total_variation: 0.0001\n",
      "   signed: True\n",
      "   boxed: True\n",
      "   restarts: 1\n",
      "   init: randn\n"
     ]
    }
   ],
   "source": [
    "# ë…¼ë¬¸ Table 1 ê¸°ì¤€ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "attack_config = {\n",
    "    'cost_fn':         'sim',\n",
    "    'optimizer':       'adam',\n",
    "    'lr':              0.1,\n",
    "    'lr_decay':        True,\n",
    "    'max_iterations':  3000,\n",
    "    'total_variation': 1e-4,\n",
    "    'signed':          False,\n",
    "    'boxed':           True,\n",
    "    'restarts':        1,\n",
    "    'init':            'randn',\n",
    "}\n",
    "\n",
    "print(\"âœ… ê³µê²© ì„¤ì • ì™„ë£Œ\")\n",
    "for k, v in attack_config.items():\n",
    "    print(f\"   {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. ëª¨ë¸ ë¡œë“œ\n",
    "\n",
    "ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ Transformer ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "- **Swin-T**: 27.51M params (ResNet-50ê³¼ ë¹„êµ ê·¸ë£¹)\n",
    "- **Swin-S**: 48.80M params (ResNet-101ê³¼ ë¹„êµ ê·¸ë£¹)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers httpx --upgrade --force-reinstall -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5. ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "### 5-A. CIFAR-10 (32Ã—32)\n",
    "CIFAR-10ì€ torchvisionìœ¼ë¡œ ìë™ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CIFAR-10 ì´ë¯¸ì§€ ë¡œë“œ: index=0, class='cat', shape=torch.Size([1, 3, 32, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/lib/python3.12/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  entry = pickle.load(f, encoding=\"latin1\")\n"
     ]
    }
   ],
   "source": [
    "def load_cifar10_sample(index=0):\n",
    "    \"\"\"CIFAR-10ì—ì„œ íŠ¹ì • ì¸ë±ìŠ¤ì˜ ì´ë¯¸ì§€ë¥¼ ë¡œë“œ.\"\"\"\n",
    "    cfg = DATASET_CONFIGS['cifar10']\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cfg['mean'], cfg['std']),\n",
    "    ])\n",
    "    \n",
    "    dataset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform\n",
    "    )\n",
    "    \n",
    "    img, label = dataset[index]\n",
    "    img = img.unsqueeze(0).to(device)       # (1, 3, 32, 32)\n",
    "    label = torch.tensor([label], device=device)\n",
    "    \n",
    "    class_names = dataset.classes\n",
    "    print(f\"âœ… CIFAR-10 ì´ë¯¸ì§€ ë¡œë“œ: index={index}, \"\n",
    "          f\"class='{class_names[label.item()]}', shape={img.shape}\")\n",
    "    \n",
    "    return img, label, 'cifar10'\n",
    "\n",
    "# CIFAR-10 ìƒ˜í”Œ ë¡œë“œ (ì¸ë±ìŠ¤ ë³€ê²½ ê°€ëŠ¥)\n",
    "cifar_img, cifar_label, cifar_dataset = load_cifar10_sample(index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_for_swin(index=0):\n",
    "    \"\"\"CIFAR-10 ì´ë¯¸ì§€ë¥¼ 224Ã—224ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•˜ì—¬ ë¡œë“œ.\"\"\"\n",
    "    cfg_cifar = DATASET_CONFIGS['cifar10']\n",
    "    cfg_imgnet = DATASET_CONFIGS['imagenet']\n",
    "    \n",
    "    # CIFAR-10 ì›ë³¸ ë¡œë“œ (ì •ê·œí™” ì—†ì´)\n",
    "    raw_dataset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True,\n",
    "        transform=transforms.ToTensor()\n",
    "    )\n",
    "    raw_img, lbl = raw_dataset[index]\n",
    "    \n",
    "    # 224Ã—224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ í›„ ImageNet ì •ê·œí™” ì ìš©\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Normalize(cfg_imgnet['mean'], cfg_imgnet['std']),\n",
    "    ])\n",
    "    \n",
    "    img = transform(raw_img).unsqueeze(0).to(device)\n",
    "    label = torch.tensor([lbl], device=device)\n",
    "    \n",
    "    print(f\"âœ… CIFAR-10[{index}] â†’ 224Ã—224 ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ, label={lbl}\")\n",
    "    return img, label\n",
    "\n",
    "# --- ì‹¤í–‰ ---\n",
    "cifar_img, cifar_label = load_cifar10_for_swin(index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-B. ImageNet (224Ã—224)\n",
    "ImageNet ì „ì²´ ë°ì´í„°ì…‹ì´ ì—†ì–´ë„ **ë‹¨ì¼ ì´ë¯¸ì§€**ë¡œ ì‹¤í—˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**ë°©ë²• 1**: Colab ì™¼ìª½ íŒ¨ë„ì— ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œ\n",
    "**ë°©ë²• 2**: URLì—ì„œ ë‹¤ìš´ë¡œë“œ\n",
    "**ë°©ë²• 3**: ëœë¤ ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŒŒì¼ì—ì„œ ë¡œë“œ: robin.JPEG\n",
      "   shape=torch.Size([1, 3, 224, 224]), label=15\n"
     ]
    }
   ],
   "source": [
    "def load_imagenet_sample(source='url', img_path=None, label_idx=0):\n",
    "    \"\"\"\n",
    "    ImageNet í˜•ì‹ì˜ ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ë¡œë“œ.\n",
    "    \n",
    "    Args:\n",
    "        source: 'file' (ë¡œì»¬ íŒŒì¼), 'url' (ì¸í„°ë„·), 'random' (ëœë¤ ë…¸ì´ì¦ˆ)\n",
    "        img_path: source='file'ì¼ ë•Œ íŒŒì¼ ê²½ë¡œ\n",
    "        label_idx: ImageNet í´ë˜ìŠ¤ ì¸ë±ìŠ¤ (0~999)\n",
    "    \"\"\"\n",
    "    cfg = DATASET_CONFIGS['imagenet']\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(cfg['mean'], cfg['std']),\n",
    "    ])\n",
    "    \n",
    "    if source == 'file' and img_path:\n",
    "        img_pil = Image.open(img_path).convert('RGB')\n",
    "        print(f\"âœ… íŒŒì¼ì—ì„œ ë¡œë“œ: {img_path}\")\n",
    "        \n",
    "    elif source == 'url':\n",
    "        import urllib.request\n",
    "        url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/YellowLabradorLooking_new.jpg/1200px-YellowLabradorLooking_new.jpg\"\n",
    "        urllib.request.urlretrieve(url, \"sample.jpg\")\n",
    "        img_pil = Image.open(\"sample.jpg\").convert('RGB')\n",
    "        label_idx = 208  # Labrador retriever\n",
    "        print(f\"âœ… URLì—ì„œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ (Labrador Retriever)\")\n",
    "        \n",
    "    elif source == 'random':\n",
    "        img_pil = Image.fromarray(np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8))\n",
    "        print(f\"âš ï¸ ëœë¤ ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)\")\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"sourceëŠ” 'file', 'url', 'random' ì¤‘ í•˜ë‚˜\")\n",
    "    \n",
    "    img = transform(img_pil).unsqueeze(0).to(device)\n",
    "    label = torch.tensor([label_idx], device=device)\n",
    "    \n",
    "    print(f\"   shape={img.shape}, label={label_idx}\")\n",
    "    \n",
    "    return img, label, 'imagenet'\n",
    "\n",
    "# ImageNet ìƒ˜í”Œ ë¡œë“œ (ë°©ë²• ì„ íƒ)\n",
    "# img, label, dataset_name = load_imagenet_sample(source='random', label_idx=208)\n",
    "img, label, dataset_name = load_imagenet_sample(source='file', img_path='robin.JPEG', label_idx=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6. ê³µê²© ì‹¤í–‰\n",
    "\n",
    "### 6-A. CIFAR-10ì—ì„œ Swin-T ê³µê²©\n",
    "\n",
    "âš ï¸ **ì¤‘ìš”**: Swin-Tì˜ ê¸°ë³¸ ì…ë ¥ í¬ê¸°ëŠ” 224Ã—224ì…ë‹ˆë‹¤.\n",
    "CIFAR-10(32Ã—32)ì„ ì‚¬ìš©í•˜ë ¤ë©´ **ì´ë¯¸ì§€ë¥¼ 224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ**í•˜ê±°ë‚˜,\n",
    "**ëª¨ë¸ì˜ patch embeddingì„ ìˆ˜ì •**í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë…¼ë¬¸ì—ì„œëŠ” CIFAR-10ì„ 32Ã—32 ê·¸ëŒ€ë¡œ ì‚¬ìš©í–ˆìœ¼ë¯€ë¡œ,\n",
    "ëª¨ë¸ì˜ ì…ë ¥ë¶€ë¥¼ ìˆ˜ì •í•˜ëŠ” ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "class HFModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, hf_model):\n",
    "        super().__init__()\n",
    "        self.model = hf_model\n",
    "    def forward(self, x):\n",
    "        return self.model(x).logits\n",
    "\n",
    "model = HFModelWrapper(\n",
    "    AutoModelForImageClassification.from_pretrained(\n",
    "        \"nielsr/swin-tiny-patch4-window7-224-finetuned-cifar10\"\n",
    "    )\n",
    ").to(device).eval()\n",
    "\n",
    "#cifar_img, cifar_label = load_cifar10_for_swin(index=0)\n",
    "\n",
    "print(f\"ëª¨ë¸ í´ë˜ìŠ¤ ìˆ˜: {list(model.modules())[-1]}\")\n",
    "print(f\"label: {cifar_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 ê³µê²© ì‹¤í–‰\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸš€ CIFAR-10 on Swin-T ê³µê²© ì‹œì‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "reconstructed, metrics, stats = run_attack(\n",
    "    model=model,\n",
    "    image=cifar_img,\n",
    "    label=cifar_label,\n",
    "    dataset='imagenet',  # ë¦¬ì‚¬ì´ì¦ˆí–ˆìœ¼ë¯€ë¡œ ImageNet ì •ê·œí™” ì‚¬ìš©\n",
    "    config=attack_config,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ì‹œê°í™”\n",
    "ds_cfg = DATASET_CONFIGS['imagenet']\n",
    "dm = torch.tensor(ds_cfg['mean'], device=device).view(1, 3, 1, 1)\n",
    "ds = torch.tensor(ds_cfg['std'], device=device).view(1, 3, 1, 1)\n",
    "\n",
    "visualize_result(cifar_img, reconstructed, dm, ds, metrics,\n",
    "                 save_path='cifar10_swin_t_result.png')\n",
    "plot_cost_history(stats['history'], save_path='cifar10_swin_t_cost.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-B. ImageNetì—ì„œ Swin-T ê³µê²©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 186/233 [00:00<00:00, 846.83it/s, Materializing param=swin.encoder.layers.2.blocks.5.intermediate.dense.weight]                  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 233/233 [00:00<00:00, 861.60it/s, Materializing param=swin.layernorm.weight]                                                     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "#ì´ë¯¸ì§€ë„· ëª¨ë¸ ë¡œë“œ\n",
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "class HFModelWrapper(torch.nn.Module):\n",
    "    def __init__(self, hf_model):\n",
    "        super().__init__()\n",
    "        self.model = hf_model\n",
    "    def forward(self, x):\n",
    "        return self.model(x).logits\n",
    "\n",
    "model = HFModelWrapper(\n",
    "    AutoModelForImageClassification.from_pretrained(\n",
    "        \"microsoft/swin-tiny-patch4-window7-224\"\n",
    "    )\n",
    ").to(device).eval()\n",
    "\n",
    "# forward í…ŒìŠ¤íŠ¸\n",
    "with torch.no_grad():\n",
    "    out = model(img)\n",
    "    print(out.shape)  # torch.Size([1, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸš€ ImageNet on Swin-T ê³µê²© ì‹œì‘\n",
      "============================================================\n",
      "ğŸ“Š Gradient norm: 1.6984e+00\n",
      "  [Restart 1/1] Iter     0/3000 | Cost: 0.893411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Restart 1/1] Iter   500/3000 | Cost: 0.078749\n",
      "  [Restart 1/1] Iter  1000/3000 | Cost: 0.081242\n",
      "  [Restart 1/1] Iter  1500/3000 | Cost: 0.055176\n"
     ]
    }
   ],
   "source": [
    "# ImageNet ê³µê²© ì‹¤í–‰\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸš€ ImageNet on Swin-T ê³µê²© ì‹œì‘\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "reconstructed, metrics, stats = run_attack(\n",
    "    model=model,\n",
    "    image=img,\n",
    "    label=label,\n",
    "    dataset='imagenet',\n",
    "    config=attack_config,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# ì‹œê°í™”\n",
    "ds_cfg = DATASET_CONFIGS['imagenet']\n",
    "dm = torch.tensor(ds_cfg['mean'], device=device).view(1, 3, 1, 1)\n",
    "ds_tensor = torch.tensor(ds_cfg['std'], device=device).view(1, 3, 1, 1)\n",
    "\n",
    "visualize_result(img, reconstructed, dm, ds_tensor, metrics,\n",
    "                 save_path='imagenet_swin_t_result.png')\n",
    "plot_cost_history(stats['history'], save_path='imagenet_swin_t_cost.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7. ë…¼ë¬¸ ì¬í˜„: ì—¬ëŸ¬ ëª¨ë¸ Ã— ë°ì´í„°ì…‹ ë¹„êµ ì‹¤í—˜\n",
    "\n",
    "ë…¼ë¬¸ Table 5ë¥¼ ì¬í˜„í•©ë‹ˆë‹¤. ì—¬ëŸ¬ ì´ë¯¸ì§€ì— ëŒ€í•´ ê³µê²©ì„ ë°˜ë³µí•˜ê³  í‰ê· /í‘œì¤€í¸ì°¨ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_attacks_simple(\n",
    "    model_configs: list,\n",
    "    max_iterations: int = 3000,\n",
    "    device: str = 'cuda',\n",
    "    save_results: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ ëª¨ë¸ë¡œ ì´ë¯¸ ë¡œë“œëœ ì´ë¯¸ì§€ ê³µê²©.\n",
    "    \n",
    "    Args:\n",
    "        model_configs: [\n",
    "            {'name': 'Swin-T-CIFAR10', 'path': '...', 'image': cifar_img, 'label': cifar_label, 'dataset': 'cifar10'},\n",
    "            {'name': 'Swin-T-ImageNet', 'path': '...', 'image': img, 'label': label, 'dataset': 'imagenet'},\n",
    "        ]\n",
    "        max_iterations: ê³µê²© iteration ìˆ˜\n",
    "        device: 'cuda' or 'cpu'\n",
    "        save_results: ê²°ê³¼ ì €ì¥ ì—¬ë¶€\n",
    "    \n",
    "    Returns:\n",
    "        results, summary_df\n",
    "    \"\"\"\n",
    "    from transformers import AutoModelForImageClassification\n",
    "    import pandas as pd\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ğŸš€ Multiple Model Attack\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total models: {len(model_configs)}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    attack_config = {\n",
    "        'cost_fn': 'sim',\n",
    "        'optimizer': 'adam',\n",
    "        'lr': 0.1,\n",
    "        'lr_decay': True,\n",
    "        'max_iterations': max_iterations,\n",
    "        'total_variation': 1e-4,\n",
    "        'signed': False,\n",
    "        'boxed': True,\n",
    "        'restarts': 1,\n",
    "        'init': 'randn',\n",
    "    }\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for model_config in model_configs:\n",
    "        model_name = model_config['name']\n",
    "        model_path = model_config['path']\n",
    "        test_image = model_config['image']\n",
    "        test_label = model_config['label']\n",
    "        dataset = model_config['dataset']\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"ğŸ“¦ {model_name}\")\n",
    "        print(f\"   Path: {model_path}\")\n",
    "        print(f\"   Dataset: {dataset}\")\n",
    "        print(f\"   Image shape: {test_image.shape}\")\n",
    "        print(f\"   Label: {test_label.item()}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # ëª¨ë¸ ë¡œë“œ\n",
    "        try:\n",
    "            class HFModelWrapper(torch.nn.Module):\n",
    "                def __init__(self, hf_model):\n",
    "                    super().__init__()\n",
    "                    self.model = hf_model\n",
    "                def forward(self, x):\n",
    "                    return self.model(x).logits\n",
    "            \n",
    "            model = HFModelWrapper(\n",
    "                AutoModelForImageClassification.from_pretrained(model_path)\n",
    "            ).to(device).eval()\n",
    "            \n",
    "            print(f\"âœ… Model loaded!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to load model: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # ê³µê²© ì‹¤í–‰\n",
    "        try:\n",
    "            print(f\"ğŸ”´ Attacking...\")\n",
    "            \n",
    "            reconstructed, metrics, stats = run_attack(\n",
    "                model=model,\n",
    "                image=test_image,\n",
    "                label=test_label,\n",
    "                dataset=dataset,\n",
    "                config=attack_config,\n",
    "                verbose=True\n",
    "            )\n",
    "            \n",
    "            # ê²°ê³¼ ì €ì¥\n",
    "            all_results.append({\n",
    "                'Model': model_name,\n",
    "                'Dataset': dataset.upper(),\n",
    "                'Label': test_label.item(),\n",
    "                'MSE': metrics['mse'],\n",
    "                'PSNR': metrics['psnr'],\n",
    "                'SSIM': metrics['ssim'],\n",
    "                'LPIPS': metrics['lpips'],\n",
    "                'Final_Cost': stats['history'][-1],\n",
    "                'Reconstructed': reconstructed.cpu()\n",
    "            })\n",
    "            \n",
    "            print(f\"\\nğŸ“Š Results:\")\n",
    "            print(f\"   PSNR:  {metrics['psnr']:.2f} dB\")\n",
    "            print(f\"   SSIM:  {metrics['ssim']:.4f}\")\n",
    "            print(f\"   LPIPS: {metrics['lpips']:.4f}\")\n",
    "            \n",
    "            # ì‹œê°í™” ì €ì¥\n",
    "            if save_results:\n",
    "                save_dir = f'./results/{dataset}'\n",
    "                os.makedirs(save_dir, exist_ok=True)\n",
    "                \n",
    "                dm = torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 3, 1, 1)\n",
    "                ds = torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 3, 1, 1)\n",
    "                \n",
    "                visualize_result(\n",
    "                    test_image, reconstructed, dm, ds, metrics,\n",
    "                    save_path=f'{save_dir}/{model_name}.png'\n",
    "                )\n",
    "                print(f\"   ğŸ’¾ Saved: {save_dir}/{model_name}.png\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Attack failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ğŸ“Š Summary\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # DataFrame ìƒì„±\n",
    "    summary_data = [{k: v for k, v in r.items() if k != 'Reconstructed'} for r in all_results]\n",
    "    df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    print(\"\\nëª¨ë¸ë³„ ê²°ê³¼:\")\n",
    "    print(df[['Model', 'Dataset', 'PSNR', 'SSIM', 'LPIPS']].to_string(index=False))\n",
    "    \n",
    "    # ìµœê³  ì„±ëŠ¥\n",
    "    best = df.loc[df['PSNR'].idxmax()]\n",
    "    print(f\"\\nğŸ† Best: {best['Model']} (PSNR: {best['PSNR']:.2f} dB)\")\n",
    "    \n",
    "    # CSV ì €ì¥\n",
    "    if save_results:\n",
    "        df.to_csv('./results/attack_comparison.csv', index=False)\n",
    "        print(f\"\\nğŸ’¾ Saved: ./results/attack_comparison.csv\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"âœ… All attacks completed!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return all_results, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ì‚¬ìš©ë²•\n",
    "# ============================================\n",
    "\n",
    "# ì´ë¯¸ ë¡œë“œëœ ì´ë¯¸ì§€ ìˆë‹¤ê³  ê°€ì •:\n",
    "# - img, label (ImageNet)\n",
    "# - cifar_img, cifar_label (CIFAR10)\n",
    "\n",
    "model_configs = [\n",
    "    {\n",
    "        'name': 'Swin-T-CIFAR10-acc99',\n",
    "        'path': './checkpoints/swin-tiny-cifar10-acc99',\n",
    "        'image': cifar_img,\n",
    "        'label': cifar_label,\n",
    "        'dataset': 'imagenet'  # ì •ê·œí™” ë°©ì‹\n",
    "    },\n",
    "    {\n",
    "        'name': 'Swin-T-CIFAR10-public',\n",
    "        'path': 'nielsr/swin-tiny-patch4-window7-224-finetuned-cifar10',\n",
    "        'image': cifar_img,\n",
    "        'label': cifar_label,\n",
    "        'dataset': 'imagenet'\n",
    "    },\n",
    "    {\n",
    "        'name': 'ResNet34-CIFAR10',\n",
    "        'path': 'jialicheng/cifar10_resnet-34',\n",
    "        'image': cifar_img,\n",
    "        'label': cifar_label,\n",
    "        'dataset': 'imagenet'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Swin-T-ImageNet',\n",
    "        'path': 'microsoft/swin-tiny-patch4-window7-224',\n",
    "        'image': img,\n",
    "        'label': label,\n",
    "        'dataset': 'imagenet'\n",
    "    },\n",
    "]\n",
    "\n",
    "# ì‹¤í–‰\n",
    "results, summary_df = run_multiple_attacks_simple(\n",
    "    model_configs=model_configs,\n",
    "    max_iterations=3000,\n",
    "    device='cuda',\n",
    "    save_results=True\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(summary_df[['Model', 'PSNR', 'SSIM']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8. ì „ì²´ ë¹„êµ ì‹¤í—˜ (ë…¼ë¬¸ Table 5 ì¬í˜„)\n",
    "\n",
    "âš ï¸ ì´ ì…€ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤ (ëª¨ë¸ 4ê°œ Ã— ì´ë¯¸ì§€ ì—¬ëŸ¬ ì¥).\n",
    "Colab Pro GPU ê¸°ì¤€ ì•½ 1~2ì‹œê°„ ì†Œìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë…¼ë¬¸ Table 5 ì¬í˜„: 4ê°œ ëª¨ë¸ Ã— CIFAR-10 ë¹„êµ\n",
    "# (ImageNetì€ ì „ì²´ ë°ì´í„°ì…‹ì´ í•„ìš”í•˜ë¯€ë¡œ ëœë¤ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´)\n",
    "\n",
    "# ì‹¤í–‰í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”:\n",
    "\n",
    "# architectures = ['resnet50', 'swin_t', 'resnet101', 'swin_s']\n",
    "# all_results = {}\n",
    "# \n",
    "# for arch in architectures:\n",
    "#     all_results[arch] = batch_experiment(arch, 'cifar10', num_samples=10)\n",
    "# \n",
    "# # ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"ğŸ“‹ ë…¼ë¬¸ Table 5 ìŠ¤íƒ€ì¼ ê²°ê³¼\")\n",
    "# print(\"=\" * 70)\n",
    "# print(f\"{'Model':>12s} | {'MSE â†“':>14s} | {'PSNR â†‘':>14s} | {'LPIPS â†“':>14s} | {'SSIM â†‘':>14s}\")\n",
    "# print(\"-\" * 70)\n",
    "# for arch in architectures:\n",
    "#     r = all_results[arch]\n",
    "#     print(f\"{arch:>12s} | \"\n",
    "#           f\"{np.mean(r['mse']):.4f}Â±{np.std(r['mse']):.4f} | \"\n",
    "#           f\"{np.mean(r['psnr']):.2f}Â±{np.std(r['psnr']):.2f} | \"\n",
    "#           f\"{np.mean(r['lpips']):.4f}Â±{np.std(r['lpips']):.4f} | \"\n",
    "#           f\"{np.mean(r['ssim']):.4f}Â±{np.std(r['ssim']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì°¸ê³  ì‚¬í•­\n",
    "\n",
    "### inversefed vs ì´ êµ¬í˜„ì˜ ì°¨ì´ì \n",
    "\n",
    "| í•­ëª© | inversefed | ì´ êµ¬í˜„ |\n",
    "|------|-----------|---------|\n",
    "| ëª¨ë¸ ì§€ì› | ResNet ì¤‘ì‹¬ (BN ì²˜ë¦¬ ë“±) | **ì–´ë–¤ ëª¨ë¸ì´ë“  ê°€ëŠ¥** |\n",
    "| ì˜ì¡´ì„± | inversefed íŒ¨í‚¤ì§€ í•„ìš” | **PyTorchë§Œ í•„ìš”** |\n",
    "| cost function | sim, l2 ë“± ì—¬ëŸ¬ ê°œ | sim, l2 (í•µì‹¬ë§Œ) |\n",
    "| LR scheduler | MultiStepLR | MultiStepLR (ë™ì¼) |\n",
    "| signed gradient | âœ… | âœ… |\n",
    "| boxed constraint | âœ… | âœ… |\n",
    "| multi-image | ì§€ì› | 1ì¥ ê¸°ë³¸ (í™•ì¥ ê°€ëŠ¥) |\n",
    "\n",
    "### ë””ë²„ê¹… íŒ\n",
    "\n",
    "1. **PSNRì´ 10 ì´í•˜**: ê³µê²© ì‹¤íŒ¨. `restarts`ë¥¼ ëŠ˜ë¦¬ê±°ë‚˜ `max_iterations`ë¥¼ ì¦ê°€\n",
    "2. **CUDA OOM**: `max_iterations`ë¥¼ ì¤„ì´ê±°ë‚˜ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì„\n",
    "3. **LPIPS ì„¤ì¹˜ ì•ˆ ë¨**: `pip install lpips`\n",
    "4. **CIFAR-10 on Swin-Tê°€ ì˜ ì•ˆ ë¨**: 32â†’224 ë¦¬ì‚¬ì´ì¦ˆ ì‹œ ì •ë³´ ì†ì‹¤ì´ ìˆì„ ìˆ˜ ìˆìŒ\n",
    "\n",
    "### í•µì‹¬ ì½”ë“œ êµ¬ì¡°\n",
    "\n",
    "```\n",
    "gradient_inversion.py\n",
    "â”œâ”€â”€ DATASET_CONFIGS          # ë°ì´í„°ì…‹ ì •ê·œí™” ìƒìˆ˜\n",
    "â”œâ”€â”€ DEFAULT_ATTACK_CONFIG    # ë…¼ë¬¸ Table 1 í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "â”œâ”€â”€ cost_fn_cosine_sim()     # inversefedì˜ 'sim' ì¬êµ¬í˜„\n",
    "â”œâ”€â”€ total_variation()        # TV ì •ê·œí™”\n",
    "â”œâ”€â”€ extract_gradients()      # ì„œë²„ê°€ ë°›ëŠ” gradient\n",
    "â”œâ”€â”€ GradientInversionAttack  # í•µì‹¬ ê³µê²© í´ë˜ìŠ¤\n",
    "â”‚   â”œâ”€â”€ __init__()\n",
    "â”‚   â”œâ”€â”€ _initialize_dummy()  # ë”ë¯¸ ì´ë¯¸ì§€ ì´ˆê¸°í™”\n",
    "â”‚   â”œâ”€â”€ _get_valid_bounds()  # boxed constraint ë²”ìœ„\n",
    "â”‚   â””â”€â”€ reconstruct()        # â­ ë©”ì¸ ê³µê²© ë£¨í”„\n",
    "â”œâ”€â”€ compute_all_metrics()    # MSE/PSNR/SSIM/LPIPS\n",
    "â”œâ”€â”€ visualize_result()       # ê²°ê³¼ ì‹œê°í™”\n",
    "â””â”€â”€ run_attack()             # ì›ìŠ¤í†± í¸ì˜ í•¨ìˆ˜\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "unlv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
